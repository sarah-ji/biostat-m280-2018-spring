{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biostat M280 Homework 2\n",
    "# Sarah Ji\n",
    "**Due May 11 @ 11:59PM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. Nonnegative Matrix Factorization\n",
    "\n",
    "Nonnegative matrix factorization (NNMF) was introduced by [Lee and Seung (1999)](https://www.nature.com/articles/44565) as an analog of principal components and vector quantization with applications in data compression and clustering. In this homework we consider algorithms for fitting NNMF and (optionally) high performance computing using graphical processing units (GPUs).\n",
    "In mathematical terms, one approximates a data matrix $\\mathbf{X} \\in \\mathbb{R}^{m \\times n}$ with nonnegative entries $x_{ij}$ by a product of two low-rank matrices $\\mathbf{V} \\in \\mathbb{R}^{m \\times r}$ and $\\mathbf{W} \\in \\mathbb{R}^{r \\times n}$ with nonnegative entries $v_{ik}$ and $w_{kj}$. Consider minimization of the squared Frobenius norm\n",
    "$$\n",
    "\tL(\\mathbf{V}, \\mathbf{W}) = \\|\\mathbf{X} - \\mathbf{V} \\mathbf{W}\\|_{\\text{F}}^2 = \\sum_i \\sum_j \\left(x_{ij} - \\sum_k v_{ik} w_{kj} \\right)^2, \\quad v_{ik} \\ge 0, w_{kj} \\ge 0,\n",
    "$$\n",
    "which should lead to a good factorization. Later in the course we will learn how to derive a majorization-minimization (MM) algorithm with iterative updates\n",
    "$$\n",
    "\tv_{ik}^{(t+1)} = v_{ik}^{(t)} \\frac{\\sum_j x_{ij} w_{kj}^{(t)}}{\\sum_j b_{ij}^{(t)} w_{kj}^{(t)}}, \\quad \\text{where } b_{ij}^{(t)} = \\sum_k v_{ik}^{(t)} w_{kj}^{(t)},\n",
    "$$\n",
    "$$\n",
    "\tw_{kj}^{(t+1)} = w_{kj}^{(t)} \\frac{\\sum_i x_{ij} v_{ik}^{(t+1)}}{\\sum_i b_{ij}^{(t+1/2)} v_{ik}^{(t+1)}}, \\quad \\text{where } b_{ij}^{(t+1/2)} = \\sum_k v_{ik}^{(t+1)} w_{kj}^{(t)}\n",
    "$$\n",
    "that drive the objective $L^{(t)} = L(\\mathbf{V}^{(t)}, \\mathbf{W}^{(t)})$ downhill. Superscript $t$ indicates iteration number. Efficiency (both speed and memory) will be the most important criterion when grading this problem.\n",
    "\n",
    "\n",
    "1. Implement the algorithm with arguments: $\\mathbf{X}$ (data, each row is a vectorized image), rank $r$, convergence tolerance, and optional starting point.\n",
    "```julia\n",
    "function nnmf(\n",
    "    X::Matrix, \n",
    "    r::Int;\n",
    "    maxiter::Int=1000, \n",
    "    tol::eltype(X)=1e-4,\n",
    "    V::Matrix{eltype(X)}=rand(size(X, 1), r),\n",
    "    W::Matrix{eltype(X)}=rand(r, size(X, 2))\n",
    "    )\n",
    "    # implementation\n",
    "    # Output\n",
    "    return V, W\n",
    "end\n",
    "```\n",
    "\n",
    "0. Database 1 from the [MIT Center for Biological and Computational Learning (CBCL)](http://cbcl.mit.edu) reduces to a matrix $\\mathbf{X}$ containing $m = 2,429$ gray-scale face images with $n = 19 \\times 19 = 361$ pixels per face. Each image (row) is scaled to have mean and standard deviation 0.25.  \n",
    "Read in the [`nnmf-2429-by-361-face.txt`](http://hua-zhou.github.io/teaching/biostatm280-2018spring/hw/hw2/nnmf-2429-by-361-face.txt) file, e.g., using [`readdlm()`](https://docs.julialang.org/en/stable/stdlib/io-network/#Base.DataFmt.readdlm-Tuple{Any,Char,Type,Char}) function, and display a couple sample images, e.g., using [ImageView.jl](https://github.com/JuliaImages/ImageView.jl) package.\n",
    "\n",
    "0. Report the run times, using `@time`, of your function for fitting NNMF on the MIT CBCL face data set at ranks $r=10, 20, 30, 40, 50$. For ease of comparison (and grading), please start your algorithm with the provided $\\mathbf{V}^{(0)}$ (first $r$ columns of [`V0.txt`](http://hua-zhou.github.io/teaching/biostatm280-2018spring/hw/hw2/V0.txt)) and $\\mathbf{W}^{(0)}$ (first $r$ rows of [`W0.txt`](http://hua-zhou.github.io/teaching/biostatm280-2018spring/hw/hw2/W0.txt)) and stopping criterion\n",
    "$$\n",
    "\t\\frac{|L^{(t+1)} - L^{(t)}|}{|L^{(t)}| + 1} \\le 10^{-4}.\n",
    "$$\n",
    "\n",
    "0. Choose an $r \\in \\{10, 20, 30, 40, 50\\}$ and start your algorithm from a different $\\mathbf{V}^{(0)}$ and $\\mathbf{W}^{(0)}$. Do you obtain the same objective value and $(\\mathbf{V}, \\mathbf{W})$? Explain what you find.\n",
    "\n",
    "0. For the same $r$, start your algorithm from $v_{ik}^{(0)} = w_{kj}^{(0)} = 1$ for all $i,j,k$. Do you obtain the same objective value and $(\\mathbf{V}, \\mathbf{W})$? Explain what you find.\n",
    "\n",
    "0. Plot the basis images (rows of $\\mathbf{W}$) at rank $r=50$. What do you find?\n",
    "\n",
    "0. (Optional) Investigate the GPU capabilities of Julia. Report the speed gain of your GPU code over CPU code at ranks $r=10, 20, 30, 40, 50$. Make sure to use the same starting point as in part 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.1 Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nnmf (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using for loop\n",
    "function nnmf(\n",
    "        X::Matrix{T},\n",
    "        r::Integer;\n",
    "        maxiter::Integer=1000, \n",
    "        tol::Number=1e-4,\n",
    "        V::Matrix{T}=rand(T, size(X, 1), r),\n",
    "        W::Matrix{T}=rand(T, r, size(X, 2))\n",
    "        ) where T <: AbstractFloat\n",
    "    #implementation\n",
    "    m, n = size(X)\n",
    "    A = zeros(X)\n",
    "    MR_1 = zeros(m, r)\n",
    "    MR_2 = zeros(m, r)\n",
    "    RR = zeros(r, r)\n",
    "    RN_1 = zeros(r, n)\n",
    "    RN_2 = zeros(r, n)\n",
    "    A_mul_B!(A, V, W)\n",
    "    A .= X .- A\n",
    "    l_last = abs2(vecnorm(A, 2))\n",
    "    \n",
    "    for i in 1:maxiter\n",
    "        A_mul_Bt!(MR_1, X, W)\n",
    "        BLAS.syrk!('U', 'N', 1.0, W, 0.0, RR)\n",
    "        V .= V .* MR_1 ./ BLAS.symm!('R', 'U', 1.0, RR, V, 0.0, MR_2)\n",
    "\n",
    "        At_mul_B!(RN_1, V, X)\n",
    "        BLAS.syrk!('U', 'T', 1.0, V, 0.0, RR)\n",
    "        W .= W .* RN_1 ./ BLAS.symm!('L', 'U', 1.0, RR, W, 0.0, RN_2)\n",
    "\n",
    "        A_mul_B!(A, V, W)\n",
    "        A .= X .- A\n",
    "        l_new = abs2(vecnorm(A, 2))\n",
    "        if (abs(l_new - l_last) / (abs(l_last) + 1)) <= tol\n",
    "            break\n",
    "        end\n",
    "        l_last = l_new\n",
    "    end\n",
    "    \n",
    "    return V, W\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nnmf2 (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compared nnmf to nnmf2 which uses while loop instead of for loop\n",
    "# the performance is not as good so I will use nnmf as the final function implementation.\n",
    "function nnmf2(\n",
    "        X::Matrix{T},\n",
    "        r::Integer;\n",
    "        maxiter::Integer=1000, \n",
    "        tol::Number=1e-4,\n",
    "        V::Matrix{T}=rand(T, size(X, 1), r),\n",
    "        W::Matrix{T}=rand(T, r, size(X, 2))\n",
    "        ) where T <: AbstractFloat\n",
    "    #implementation\n",
    "    m, n = size(X)\n",
    "    A = zeros(X)\n",
    "    MR_1 = zeros(m, r)\n",
    "    MR_2 = zeros(m, r)\n",
    "    RR = zeros(r, r)\n",
    "    RN_1 = zeros(r, n)\n",
    "    RN_2 = zeros(r, n)\n",
    "    l_new = abs2(vecnorm(X - V * W, 2))\n",
    "    l_last = 0.0\n",
    "    count = 0\n",
    "    \n",
    "    while (abs(l_new - l_last) / (abs(l_last) + 1)) > tol && count < maxiter\n",
    "        l_last = l_new\n",
    "        count += 1\n",
    "        \n",
    "        A_mul_Bt!(MR_1, X, W)\n",
    "        BLAS.syrk!('U','N', 1.0, W, 0.0, RR)\n",
    "        V .= V .* MR_1 ./ BLAS.symm!('R', 'U', 1.0, RR, V, 0.0, MR_2)\n",
    "\n",
    "        At_mul_B!(RN_1, V, X)\n",
    "        BLAS.syrk!('U','T', 1.0, V, 0.0, RR)\n",
    "        W .= W .* RN_1 ./ BLAS.symm!('L', 'U', 1.0, RR, W, 0.0, RN_2)\n",
    "\n",
    "        A_mul_B!(A, V, W)\n",
    "        A .= X .- A\n",
    "        l_new = abs2(vecnorm(A, 2))\n",
    "    end\n",
    "    return V, W\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have implemented an algorithm with arguments: `X` (data, each row is a vectorized image), rank  `r`, convergence tolerance `tol`, and optional starting points `V` and `W`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.2 Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiIAAACECAYAAACtbkDwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAIABJREFUeJztnXmUXVWd739nuGPdmqebqlSSylQVkpDKQEISIQk0oaMiq0UFeSjqsh+D+poFrSs8Wo2tEh+sjvR6kCe81wq28hr1yaCiTdSQGUggExlJUklqnqvuPJzh/VGkbv327yS3qnIr51T4fdaqtbJPfuecffZv7333Pft7fz/JNE0TGIZhGIZhbEC2uwIMwzAMw3x04YUIwzAMwzC2wQsRhmEYhmFsgxciDMMwDMPYBi9EGIZhGIaxDV6IMAzDMAxjG7wQYRiGYRjGNnghwjAMwzCMbfBChGEYhmEY2+CFCMMwDMMwtjFuC5HNmzdDbW0teL1eWLx4MezYsWO8bsWMAvaLc2HfOBf2jTNhv1wdqONx0Zdeegkeeugh2Lx5M6xcuRKeffZZWLduHRw9ehSmTJlyyXMNw4DW1lbIz88HSZLGo3ofSUzThF/+8pdj9gsA+2Y8ME0TwuEw7Nixg33jMHLhG/bL+MDzmTO5MGaqqqpAlkfxnsMcB5YuXWref//96Fh9fb25fv36rOc2NTWZAMB/4/R3zz33jMkv7Jvx/WtoaBjzmGHfONc37Jfx/eP5zJl/TU1NI/LBBXL+RiSVSsG7774L69evR8fXrl0Lu3fvJvbJZBKSyeRQ2fwwGfANDQ+DqniGjncvCKDz+ubr5FozZ7ahcoEnQWx6E35Unl/USmw+ln8SlRd5uoiNyPZEDTn2+P51+ECHl9iU7zVR2d+VIja99fi88v0RYiPH0qisH/sAlVOQhN3wJ7j11lvR8Yv5BeDivrluzaOgqpk6RatxN1KSQOivw+V0eZrYXDujCZX/puwYsVnrP4XKPbqL2PhlDZWrFGrTqeN2/lVoIbHZ1T0DlRuPTyI2ahSv+n3t9JuVmsA+zmvJ1E/TErB360Y4fPgwfOc730F2Y/HNjb47QJUyzysXFaLztEkl5Fr99XhsRSbTZ0hUYX+VVQ8Qm2tLW1C5xBWzrPtwfArt70UqPm+2u43YzHKFULlaDRCbpInrfChJv6Ftjdaj8v7+zDdpLZqCP3/mhVH55mJ+qfvKd0BxZ8aM5ien0mvNxe1wzzXvEJvpnk5ULpDpnFej9qNyn0HnoYCM/RAx3MQmKhw7laLj4a2BWlR+r5HOi0orvn9wj0ZsUvkKKnt7sC9TqRjs3fVkTuazj8HHQYXMmJFUPJ8Zi3AfAQDovC4P16eA3k9oUkiVGMTGNx3342vKOoiNXxgjmkn78YHOalSO9PtofVR8f6+fzsHJBH5291HaUQMteD4LtGbaVNOSsGf3/4D8/Hxy3qXI+UKku7sbdF2HyspKdLyyshLa29uJ/caNG+F73/serZjiAVXJdNjhgxgAQPbRhYia50Fll4c6fvjiBgDAE7D4IBMGQb4n+ysmn0qbUvYLA95LJwDVhZ2qqvRe4rOrCh24soLPkyT8XEkzDgAwYr8AXMI3qhdU13DfCAsRUzwDQBYeXfYpxMaVhyc6X4C2aX4efs6kTtvLL7wSLFCoTVw4z2vQfqDGcV+RfdR/snAdxUM/xBVD8LGL+m80YwbgEr6RXKBKmXaUZY9gQJ9B7F9WzyD6S/HTDzx3APvP46ITnYjXorOIYynPQ/tKvkvwscW4SQoTdp6b2niFceJK0w/gXMxnitsLiifTzqaHmBBkv/DBYTVXeXHb+GXaVgGhbVIGbYeAMGZMCxswhMVBko5Pl4bbj8yBACAL86DVeDBc+F6qisvJZBgAcjSfgQst3iVJWIhYjRmPMGaoCcjCMJK99PNI8eNvbeIcCAAgTK8gWyxElIgwVyUt2t2F76/46XVkGfcx8TkBABS3+JlF54vRbnWNm1hVrIhpmpaVe/TRR2FgYGDor6mpidgwuWOkfgFg31xp2DfOheczZ8Jj5uog529EysrKQFEUsirt7Owkq1cAAI/HAx6PxdeD908DDFulVqSm4/P6C8UzoHcvfg0oHaZbGN62XlTevnYZsdlSfD0qh2fTb3bXzT2Dyodaq4jNjLsPkGMiahC3idZOX82Vb8NlixcOIL4fkv34lZrHkADiAB0d+PoX8wvAxX3j2fIe+gYxgi93UDQCm/g8/Ap04z98gtgcaMAitK+VbyU2tcI3GJdEvyWeSeJXl//+6hpiM/OneNtuVuPbxGYsSK7Mtx7tw+2D0YwZgIv7xkzrYEqZb5hmAX6FHJ1CX7UmSrN/e1FCeKoIx+g3pV3NeIzOq6RbKv1Cu3+s7DSx+SCOn7lPyyM2PV587VKFjvVyBb+18cv0Leps4To79cx2nKYP2udiPtM9gAaKS6hu5Vv4FT0AQPwI9tVLM24mNu4BPBskSyy2Blf1oPKXZ7xFbFblnUDlHp1udSVM/G150861xGbOk92oPKvpKLFRystQWWtuITb+4mJUTi7EfcutDLZNLuYzEVPDb2ikPQeJTXBP1ssQlPJycqzlnlmovG8pfSNSVIC36GJJagPv4M/Da/6jmZhoZ89nraOch8eapNC5UyrBs3lkfjBzj/TYlhQ5fyPidrth8eLFsGXLFnR8y5YtsGLFilzfjhkh8ocfxlu34g9u9oszaGho4DHjUNg3zkOWeT67mhiXn+8+/PDD8IUvfAGWLFkCy5cvh+eeew7Onz8P999//3jcjhkFP//5z2HFihXsF4fxta99De677z4eMw6EfeNceD67OhiXhcidd94JPT098M///M/Q1tYG8+bNg9dffx2mTp06HrdjRsHGjRvZLw7kjjvugHg8zr5xIOwb58Lz2dWBZF74DZNDCIVCUFhYCDf570Lqf1PH+7tmkv5GVF4wB5WNg/TnnyOh797lqOzvoqruh//1l6i88btfJDYFL+K9WHX6NGKjt+A9aqvnUoT9Ur2vj9iImhAjhvcVNTMNb8KrMDAwAAUFFr81GwEXfLMabkcaEVLfIqrfARfe19S7sv8k2gp1UhCVjz9Jf0K4rPYsKu85OpPYzFmPtQl6Ty+xGRHCrxSs9lTNNP2J6gVy4ReAjG/WuD6LfKOtnIfrolj8qieBx5aUtvhFWgvWGegVxcSmYwX2e7wie73TM+LkmBHCfavgBP2+VHQaj8l0gO4ydwjyLyVI73VNlfUvLAAA0tEU/Gnd/87JmJnz4OPoFwjBt7BIRI7RPhKvwT+BDFfTdqjclb3f9i7EvupYQX+9sXg+1rz1JKgup6UbawOmbrb49cZbR1BZ7H8AAF0NWF/k6aMfQcUvYBGGMgtrRDQ9CX85/a9XZD4L33k9Obb8W/in1LcXv0dsfvBf7kVlK62JMhuHCDj9RTpoChdi3U1XK1XcTXkNj+uUxXgY/jNbAIDwZKqX6f0kHiMnV71AbGb94gFUnvaHjBZL0xKwfef3R+0XzjXDMAzDMIxt8EKEYRiGYRjb4IUIwzAMwzC2wQsRhmEYhmFsY1x+NZMLjFgcDImKRC/F8a/jIDyz/57amMsXoLJiIRIr24cFYFoRjdv/0K7Po3J1ggqu0n+zGJXPrqaBaE585RVUvrWqgdhYiVNFRHGqKKIE0wCgGrUxoRQVgDJMSCwKUaGEilUNPxZGafNpdkzvMRzYSOugglajFAu1pv2UrqWPzcGi5brdNC+KVCDkQuijNsp0XMfkFJqnRRfC//taLfIARXFgLSk6TBBmpAAurpccNXJhAchyxh/uIzh65FhFwmQkttAcTRX7hbr4LYKn3TgXlbujdGxN/hMef8ah41nrZxFhG/L/A5fNlXRsfXAjFgvGZmbmAyNOw9iPFXfIRKGxIzX4uXVP9uQz6QAVGncvwX2y9CDtx4FmPMdFG2lrnRP6dm8fFasWbxMCBfZSoWz6+rnkmEj1G91ZbYyF+DqJctxempYAoLHwxoS5dB6Yw4IgiqLS/JdoALg375mNyq+foc89xUKcKoLmAgAIvk2F4s3T8OdazR9oP4hMwvN9oI1eR96GB6jFTwqgdBee81bPpR+i/tn4/sOvK5vZ0zpYwW9EGIZhGIaxDV6IMAzDMAxjG7wQYRiGYRjGNhyrEVGnVIM6LIW5di57psQ5m/pRObVmEbHRhVTg8nt0/1kuxjoEVyRGbABw4JlEkUU6+t++i8oz2uqIzbzIg6g8ZZaFYKAD76nqIZogS0QJ4D1e00wBZD9tRJipNJjDMlwa/cK+9Ah0CFYdr+8uHDioeCcNDqa9j/2Vvn1p1nuZFmnktcZzqCyJOhcAiM8oRWX3f+4jNuJzjESGo5Rm9uNN4+LBznLBWDUhuYDolgCgZy4OHBW9hgbwM57IrgkZC9IumoRy6kmciKz7E5ngd3pKB5o6bGz0zTdB9mY0It4O3CdrtlgMzoMnUbHQIjCecg3WKjR9oozYlB5NX7IMAKDdjFVARoyO0OLjWM/QtqaU2AzUYW3CrG/QRJGdX8UBI0v/D80gF7obzwW9c7EuwUjoAH8hp40J6Z33QbpEQDMrym47md1IQJkzixwzu/Fnlu+PNDBa0aTrUNn/+73ERr0J6598R6iGy/BijY+RoBooMTGexyJRXvAP5NBlw29EGIZhGIaxDV6IMAzDMAxjG7wQYRiGYRjGNnghwjAMwzCMbThWrGq6XGAqGQGRUo5FZVYiPCksiOOC+cTGFcJCLaWcirui11ahct4hKvyRFCxL1Pw0yIyIfuQEOTZ1oBrblNPMilCE01orESoykvourUSVDCVnYlW5AAfNEkWJ6uRq8RQw83BAIilBRYrxUrwuLtZpUB4RJUHloSkh6aPaQYM8GfPqUVkOR4lNz1wsYJ38Ng0BpAtCXbWWpiAnwlh35rpSjoLMXcCMRcGUxhZU6ALytfXkWKIKjyXfuX5iox/7IOu1I/Ox32dPoeLs9M04EKDnnEWG2QEhcJyFkFPKw4LtjnXUN95+7IBEaWYc68nsY3qkXHPtOXDlZfx+vAOL3VN7aSZUWHMtKiaL6HTdW4/HjIe6hWTttQp21daF+7a7k94rLYyrWCUN4ujqx/Xp/PoKYqPG8Hli4EcAgJ5rcdvrbnyOIeUuabwyZxYoSqb9xQzV5tFT5BxZyIiuzawiNlo+FsDK7TTYoSF8jikza4lN73Lct719tL0Cv8ai4D6LjMGpfNz/NZ9FJu4kblervtI/E/eNskOZMa1pCYA3XyXnZIPfiDAMwzAMYxu8EGEYhmEYxjZ4IcIwDMMwjG04ViPSdHslKJ5MAJaqbXiPOn7DdHJOeDIOEiTudwEApArxvpivgyabilZjm7zjNNiN1In3dAvP0H15UddiVlE9StsKrAmJUnkFeHtwfTQf1b7U/JEG5BqOricBOi5pMmK6b54Kijvjm7KdQkKqMlq/nrl4vz5ZTPcnS47joEq9a6YRm4IXsabAPUC1Ab5O7C+zj26cG4Juo+OB5cSm4BzeH236Kk1s5enDfaz4FNXvqII+Jjwjs9mupRMAOQwQJNVUgTRsvztWj5OZuUM0kaSk42dIeS0CwPnwd5aWteXEpmgG3jfPO02TNaoefP8iT5zYvPMFXPadmERsSo5j36TzaH8K1+A6x+uoLqmsHAunPldzeOjfiUgaNv5PcsqYiGkuULXMGK0pxX3yzMfpwA+cx/WPVtP5zPALe/hisksAABDms05qMb0KB00800Xr4+nF7ZcusLhXER6P/dX0u66rA4/Pgdl07gouxOO8uQ33YzN+eTqo4SSqAqAOS3oXL8Ufi+pMqsmIVuLnShbR/qcKU0Ghv4DY+A7hcnIqTawpRXB9eufSdi/4HQ5W1j+TtnsiiPuKKfYdAJBUrJkKtVHtkp6Pzxs+3+qp7Lo+K/iNCMMwDMMwtsELEYZhGIZhbIMXIgzDMAzD2AYvRBiGYRiGsQ3HilVjtWmQfRlRTqQRC/7EbIwAAKkpWEw1eRINhKRo+JH116iAVBQggkVgLcOFbWLltCk9QrCa+EoarEZEn07Fe6FyLO5yd9F7xaZiMWisDAua9FQC4GDW24+IaFACxZNp//insZjQsNCwxatwG6plVNTZXI19PPt5GogM8rEQVuoOExNXnAqQs1H0ARW9Nq3FIjqtmArkoim8lg9P9xIb94AQzG2YXlNP5nYImi4FTCXjADFIXM88Kj5LFeC+bE6ivrmuFot785I+YtP2Kg6Y5IpQ0bImBAk70V1BbK6txTlvb1l6lNj0abi/v9Y0n9gYMeyL2aV0PlhUjLN6z/a2Df07lh6b8M6KeNoFajozjqcXYnHopOW0r5+di7Pb5pt0zhOvU+Si88eezUtQeXjm7AtEUrivu8L0O6op4/O8ndRmZgMO/igDFdhWzbcY1wKtMRxgrUMQ6Btm7sSqkm6CNCxAmih81j20veLl+JhsVR0hWGFgVyM1WTIPlcM1Vj86EINn0jZtfQBnmrcKbJeaiz8fjbSFj1N48raKG6eGhKB1KzL1M+ImwK/oOdngNyIMwzAMw9gGL0QYhmEYhrENXogwDMMwDGMbjtWIuHpUkL2Z6nXeLux9ttA9alET4lLoHq8u7LOGLAKIlR8QNvd0mplsch2OCtR/jgZdEkkUUvFE/zx8bbdK67xoLt7HPjtAg950Gljr4ooI+5w5TOCl+0wwvcP2VEvwM5gK3VhUCrAGIz1AtQolx4VkU27aPc0w1oQoNbTdDRVfRwoEiA0IyeosA6O14zomdFofrQA/e7qI9hUxIaIay5SNRO6SdwEASLEkSMO6mSzELxP1IAAArmk4GdeNU2mSrxovDk72s3dWE5tZ23GbxqvziM3SWfja/RZaE5HF3rPkWNTEe+nL62nCvaY01ljUu9uIjch5jY6tXOBzpUF1Zb73BVTc3/626JB4ChRUYK1OyKD6I5FXexaRY3ntuBOIwekAADo6cGDFQougZ3Jc6EwWU8qsAD4xoNIgcnN9WAOkWOhI/i3yMVRORbG/jXjuskWq4RSoaqZNCgUph6vXIkhhHGtWUvm0MSr24M8jyUvnPFkIzBavoNcRA4/phkXwNCFnp7ePtk/FU/g63Q107KnCx6ysUd+0r8LXdvVlJhwjMbZ3G/xGhGEYhmEY2+CFCMMwDMMwtsELEYZhGIZhbIMXIgzDMAzD2IZzxaohCZRhAsv0GSysSU+2EBeqWPgzLb+H2Hy+9G1U/kb8LmKT9zIWA4WXUEXrfdP+HypvdN1JbCSPIHYsoyKjVYtxsKa0RTSwxhAW0EXiVPRk0ATB44akSyDrmWcxvVgE5Q5Q36T6cZ2HC5yGbITMyEp3iNjAZOyL85+kAenWfG4vKr9Zdh2xmbSpRbg3DSQUrRFEuBbLdtONbSQPFRubYSEbcGJY2+X6q4BLBVAyw9odwfWTdXrD0nysdDsVopl13/rlQlSue+EIsQmvqUflZCG9V6EQcMtKrHquH2fx/WLrV4hNnh+LIFdNpgLbWT6cbnqhhwr4PBL2zWsdmaBsyVgaAA6Qc8aCZsgARqY9an042OE0Fw22VufCY8Qj0fq/GcdtfLSvktgUCFlzk9MtAv4Jkass5xNFCGjWQ4WMtxYeRuVZLpqBuUTBz/V2gmalFedBl5BR20jkLticMhAHRcm0bWQqbp/mNbR+qVJhzuuh81mgDZ+X965FlLE0FgCnA7RNi8qwmLzfoIECZSFQpxh8DgCgdTU+LzqXinCnVuHPTPEzFQCgpx3PD3Jnpr3GGmeO34gwDMMwDGMbvBBhGIZhGMY2Rr0Q2b59O9x2221QVVUFkiTBK6+8gv7fNE3YsGEDVFVVgc/ng9WrV8ORI/Q1LpNb4mdOQ9vz/wZnf/g9OL3+EQidxK9ITXPwlV9dXR375QqT+OAMdG7+KTQ/+n049+A3IXrkMLHZuHEjj5krzM63EvCpL7bC5IZGUCadglf+iF+B85ixj76DzXDwv78COz/7HPz1ph+TMcO+uboYtUYkGo3CggUL4Mtf/jLccccd5P+feOIJ2LRpEzz//PMwe/Zs+MEPfgC33HILnDhxAvLz6d7WxfB1maC4M/tlCRybCNQ2uqd/0giicmsx3dv7bxV/ReVZpV3EJnEW79uZtbOJTYMHB+VJLYgSG5FAM93jfXTSn1D54cbP0PqksZviPXRfXelNg7+4Ckrql0LzK8+Dr8dE92s5tA0AAJ588kloaGgYs18ABoPnKMOaSO3B+7dUIQIg+fCeqjGVbiamNOG5hP1TAAAzjjUGwd0xYrMzjJN8Td7WTWygbiYqKvuoxkD9e5zELeCne6rJdHZxTiKSAnewCvKXLIXO518ANSKBp29wD/dCoLlnnnnmsscMAIAUT4AkZ8ZN4DT+cA1XF4qnQKsf7/lWbafXDf5mNypb7dDnncX3iqyg9+qI4zHpVaiPXUJQP0Wl4yb4+fOo/Pp3qA5o+lJs89XCM6gcjZlQWy/BbZ/Nh/v/az/06AnoSWeCsL3374N9IhdjpqmtFGRfJiDZn+U5uK5uOg/lSziB3OEUbc/1Bz+NylraQqsgBPhLlNDvn7fMOYbKb3pnERt9H56HXBFiAk813YLK6yro4mCRD0cMCxt0Pmtt94EWnAJFy6+Hzh//X/B2AgyPS9i+dwcA5MY3UiIJ0rAmcYm6Ko22qRLFbZjXQkxASWQPuqafPI3K039Oz4nVYR1c2QCdO9V9eKHWffdCYhOtERKPuukojgrJD/tj1DdaNw6sl9+T6V9jDZw56oXIunXrYN26dZb/Z5omPPXUU/DYY4/Bpz89OEBeeOEFqKyshBdffBHuu+++MVWSyU7+jDmQP2OO5f+ZpgkdHwx+kHzqU5+CgoIC9ssVxD9nDvjnXNw3AACPPPIIj5krzK03+WDRKuuXwqZpwrHfnAQAHjN24G+YDf4G+gUQYNA3Pe/vAgD2zdVCTjUijY2N0N7eDmvXrh065vF4YNWqVbB7927Lc5LJJIRCIfTH5JZkpBe0BP76ks0vAOybK0E6NPirgptuumnoGPvGfsItEYgLob3ZL84gFeoFLc7z2dVEThci7e3tAABQWYl/QlZZWTn0fyIbN26EwsLCob+amppcVokBgHQibHn8Un4BYN9cCfTooG8qKirQcfaNvcR74pbH2S/2o8WsFxDsm4nLuPxqRpKE5GWmSY5d4NFHH4WBgYGhv6amJks7Jvdcyi8A7JsryWjGDAD7xi7YL86FfTNxyWlAs2BwUCza3t4OkyZlsqJ2dnaStyQX8Hg84PHQAF1qzAQ1nRHd+brwmknUNQIAGIJoMpKm2T8fOHE3Kltl6PUIKQj9v32b2Hyp6GFUnn6YKrfMJA4k5O2hIqNP7n4QlVfWniE2Tf04M6ar1yIrrbCkNBQA3TU4KJV8KtoFuLRfAC7um0CrAaorI6rSvYJvymlQHn8At0XAS7NyhmM4kJAoTAUASM+ZgsryThpwKthei8r6qUZiowhiVclHO1S6Ex/zzqI+jiexuCsepu0lSt08Ayb4OgfbyEwMKvA6Ojpg9uzMnvhYfWOGwmBKmbaVB/C3x/wZNBNx5T7sC2kXbVOlHAta9S4qrjT3Y2HipEYqrgwfx+0+UEtF5xVv4m+1xRYJcY//eC4q1339XWIT/SQW7M3/3FeJTWa8/Qxe7FsEyd7BeSuhWmcFHqtfpAEXSMnM/HRKwe35a+8S8RT4tVA+1FZFbJJxIdBXlIqn45X4w7nq5bPE5o0F81A5cJJeR9krtHEtzfR7/Ch+y3C2hzpvZjnWSxW5qeBcF4IAqnEAd3hwzBimtRh1zGMmkULzp/8sDjxWWCL8UgIA4mWCWLVjBAHWXNmF7VZzlUc4phQXE5v0MtymOn1MkNJCRvY22sfDgjA8EaIX8rULweaimfleTo0tm3hO34jU1tZCMBiELVu2DB1LpVKwbds2WLFiRS5vxYwCd6AEVC/+AGK/OAN3YHBS2bp169Ax9o39eIKF4CrCC2P2izPw8Hx21THqhUgkEoEDBw7AgQOD35oaGxvhwIEDcP78eZAkCR566CF4/PHH4eWXX4b3338fvvSlL4Hf74e77747y5WZy8FIJSHR0QKJjsHfkSUjvRDraYFUpA8kSYLy+pUAAPC73/2O/XKFMZJJSLa0QLLF2jcAAJs2beIxc4UxEknoPdkDvScHw1pHWiMQPd0Byc4QSJIElR++UeExc+UxEklINbVCqmnwJ8zJSC/EelsgGR0cMxWzBxcc7Jurg1Fvzezbtw/WrFkzVH744cEtinvvvReef/55+Na3vgXxeBwefPBB6Ovrg2XLlsEbb7wx6t92M6Mj3tYE51/cPFRu3vsaAACUzlgC0274PFTMuQHaDvwnPPLII9Df389+uYIkm5qgffNPhsrN73zom5lLoGbZ3wEAwAMPPMBj5gqTPN0Kv//+a0PlfU+9AwDvQPkt82DmP34cgn+3GJp/sYvHjA2kzjVD5788N1RuevfDMTN9CUxfeRdU1t8ArYfeYN9cJUjmhUAGDiEUCkFhYSHM/8oPQXFnAqckSvH+lkX+J4jWYg1GzTQayKpzAL/S05qojmT6b/HP9tSj54iNdg0OdqX5aNAb15/xnqo6laq0wwsnoXLHEnqdsiU4eVf78Qpi4+7DL7fyz2K36qkEHHjxMRgYGICCAmvNSDYu+ObG5f8EqprxTfsK/Ao7MotqYdwFWIdgnKPtXnoI19nTb5GkTEjgFZ5G9znVuJDAy2K5XXgIJ3dKB+kE1jcbB+7pbaD1UUtwX0mHqObB14T3hivezbSPlk7Ani3fvSy/AGR8sxpuB3VYIjfJheuTvnE+OVf9C+6nsp8mRev79LWo7Oume+K+t06ist4/kLXe2s2LybGWG/G+dNIiweX0qZ2ofG4/TUw545t7UDn1tzToWevHcOdIlWSey4gnoPnh7+RkzEz9wQ9B9mb6k16AA7l5immwvHQrHiPTf0NtXB1YA6SfpnMVGLlLEJcLlLl1qHz8/iJqZOD5vgLnsQQ9lYD3XvqnnPjm5uJ7QZXouL1AqqGWHIuX4THt76R91HUUB72EJNXF6fX4cyQ0g86Lmg+3hZgcFAD0XBe1AAAPd0lEQVQgWYznvPyzxIR8ZiYtrpMS5Ceany4PvJ34vLy2YXrBVALe+9Xo/cK5ZhiGYRiGsQ1eiDAMwzAMYxu8EGEYhmEYxjZ4IcIwDMMwjG3kNKBZLsk/nwZVzQg3dQ8WE5lU0wlyHB/s2BskNlU7sJDSt+cosZEKsHAxvIpmooyX4HtJFnqwwlU4oJKx9wSxCfwVC/ry91HRZLweP4fnerp+dAnJfwMtWDylaVY5cceGevAUEncVTMICyESZRbdqx8fKjlERlDuUPVtl9wIspByYTa+jJHD7uMJUlKX5cECp4mM0WFnJERxoSY1TYWw0iMVlCtV5Qv55XEdvd0Z0qOlUgJhLzLTQD6xE1YKgVXLTwEuBZnydWJCK+8KfuSZrfYpOYcFe8xp6nfIlOKBZwE1FfmLWXqOc9u+mb+OYEjXfp3lI3NdiGzWa6ad6MofTo2QO/n2IEsZ+UBvpuJ/6o4vnTblArmSokc8uQ+XAr2kQx1yhH8Hz4KxvUJu2h7FfPAPY31o6+1wxUsx4HMzhE7iCfaN56ZjxDOCWd59oJTaaEPRPsRBvxibjCaN3Lp2rdK8gvvfQZxd/rODrpT3Df074kFDovdpW4jqKgTIBBoPLDcc17McBUtoBAc0YhmEYhmFGAy9EGIZhGIaxDV6IMAzDMAxjG47ViPhPdoIqZwIbRYOT0f9Hq+n+Vl4TXldNfp0m5oJ2HOQsvXAGMemej7UAA3Pofpsp42OufrqPmCrE1wnG6L2kCNYIaMc+IDY+De+PFhdPIzYDM/D9fcfxPrtm0H32sWLE4mBImTrln8Vaiugkut/t6ReDjFH/ibof3U1txP3J/Ea6ltYF2YF4DgCALsggwtOouEPGzW4ZRC+/GR+0DJ52CreP0plJqmXm0C9WiAHNZM1CU1NRhspaC93vVt58D5Wt4lcqM7MnGxSZcaScHJP8OJAcWNQ5Ng0HAqwppuPPf74XlRMWAc3EvJjDfW7mMA6Yu1cGxZPpq4ogaZn0L9n1ICNBTE4IACAFcN/uv24SsUkU47Gm3raU2OTtOY3KencPsckVk3aGUVmJ4HGi6bkbNwOfuBZUV6bPFb6Kkz6mCiwEiQKu9o6sNnooRI6JCVWn/TbrZSx9bJWEUkQcRfoamrTQEObFZDUNTunrwHOKMax5jDFKd/iNCMMwDMMwtsELEYZhGIZhbIMXIgzDMAzD2AYvRBiGYRiGsQ3HilX1jm6QhmUR9XfhoF7JEhp0qegDrC6UklRoo/X1obK8rY/YVGzD5UkWgWhEkatr/3FiI4qTrEK9jEQPp/f1o3J0EhVPuQfw1bXmFlw2aVvkCvksFsbmWQg/NR9e84piUQCAwM5T2KanlxrZSNcDy8kxw4VFfvlN1KNqMxb1mZFM8DTTzF2gOSvEgGayRSCoprumoXL1/+onNkYsRo6JpCbj1J2nv1lGbNxdeMrxdlFBctFpPI69v3+H2MgV+F69K2mfi5dhm/AnaNA67SyujztE65MLgu8kQB12KyU2+vHY+fUV5FisEo97NUbrb+BkxpCaQdXbpSW4bc6fKyY2eULW3JLjGrGJleG5yROis17gV2+RY4R3DqOiOKr0HM5na/9xB3gDmQlpx0tYLB04T9vr/Drc31JfpXNDxZt4XhyJeHskWAlT1eoqVDaLqJy8twH7NPZZmh070idkuY/QJYK3F88hw3+3IY9R4M1vRBiGYRiGsQ1eiDAMwzAMYxu8EGEYhmEYxjYcqxFRigpBkTOBU/x7sH4gUlVPzokG8f6k/6+dOamLVSAa5S2cLE9Pji3ATvjO61HZFaV7+J4efO2BuXR/NLgte9Cd8ULUcuSfpckG21biPUvNIjmcmRrBvq+Mn1Opp0HitCIcSE4y6D61fATv1xrhMLExVyxA5dBMeh1fh7CnanEvoxfrkKySyl0pPOeo7iZ1Iw5wdf4fGojN5L/g9pHfP01spAHcT6f8Lo/YxAXZSKiWmEDzdbgfGB+nwbW85XjfPhml4y9ZggMvaVGaYE8V9rQ9w5pHz6F8R9lxEBTp8vzu6adzQ38D1ml4jtFnDL6N28bzTDOxEYPIlZRTTZAcExIoFtEkkKkAPlZwks6duUtXlxu+VfoBFORnvpPfCrj/K4dOiaeAZ+kC4Qgd93pJIOu9lWJBx7RmNrFJ+/Aco/moDsgdxvfPa6fjITQNv3eId9H6+c7iPuqhcjFwxYU+153pF5o2ts9BfiPCMAzDMIxt8EKEYRiGYRjb4IUIwzAMwzC2wQsRhmEYhmFsw7FiVb1/AAU0MwUxaF47jZzSV4cfR18wi9gYXix2TOfRJnBFsRinf4aH2IiZYsUgLwA02FXxQRo8LVaJ14K+bmICSgLX0dNB61x4LHvwtHHDwL5Q2qgg0hXGwiir7Ltdd81D5YJGqhZUY9g3ZpTaiEG7YlVUVJeox/fSqAmYMq6jx8I3snB7X0eC2IjBwGTIKHXNcQw0Z4VVUKXKvTibZ9dC2r/6rsH+K2ukQtR0IR4n8bIRZC2N0mPpLnwduZwK4BQF+9iTR/tBohz7z91MhZyFgg5RTWSuq1kEf7OTwl/QQGBKchkqt66hQcYKz2B/Rm+lAm9Twm3l66XXAcCDRInT9ind1YbKWuM5i+s4HKEtjCjtpNV/xkEKDTcdM3JUmAtGkDU38PpBep1gBT6nmAYrS1Rh9X9vnZfYpIqxvwInqHja34E/Obz99HPW3YfHmqsvIxyXxpgVmd+IMAzDMAxjG7wQYRiGYRjGNnghwjAMwzCMbThWI2Imk2BKF9+j9W2he2l5b+PkdIkFU4hN20q8/+zrtAhS1Y33CP3dFvtkA3gPVfPR/XBvG9YGtN9YQmyKT+D9tkg13bfzdOHrVG0nJmDuP0IP2oSYcA8AoPgE3h+NTKF7mGLgnp55VJsDgI95+mlkNLHb9NcRE0gFsTbD3W7R7ngbGHzdVn0F30w9R4PoibvtZjpzxDTHmCXqIih1M0BRMm2kH/sg6zl5O0+gcrzsGmIzMBOXfctoJLJ0QAiYVEF1QGlBWpIMUo1MnhBMa2YpFed0x/GFokmq/3AdxXvp/g46n8iCc+KlmWfQU87/npb/yn5UrmukAbFO3Ie1HcWVNMhYwIPnodZemujTPI/HWvAt2p7qBNSEHEomIeAe5mszu8JOP3Iiqw0IwcrSc6cSE2VqJSrLFvo6owtPRLJFQMR4CfZXaCYxIQkRAy3Uf/lncaBAtYv2FRjACRLTddVD/9a0sSWNdP5IYxiGYRjmqoUXIgzDMAzD2AYvRBiGYRiGsQ3HaUTMD/fnNEhfMhiGZNI1lGwISZk0GtNBT+CL6il6EzF+gJm2SJqmCRqRNNWIaMJvqvUUrY+mpQUbqhkQr6Np9NmlLPEoNBj8f3ME+58XY6S+scIQfKFbVFdX8P6insy+32jlP1EjYtBmByMuJFZL0HYX7z+SvqIZNJ6FJvhGMiXyf5fjl+Hnkz43gjglponrbNVPxTbU0hb9NI37pZ6k/VQXhonoBwAAPYafIe21aNO4EDPIwjd6UuhzKYtYP8JjDNeFXGgHu8bMSBjelwAAQLfwXVzoxzEa60HTcBsbMXodM4H9aRVnRezr40Uu57NoRBjDOXoGcVxZfR6ZuhAXyaC+MYTrWMXqEMes1ZwHwjHd4nON1NEqLsglPmcvJL0brV8k83JnwBzT3NwMNTU1dlfjqqWpqQkmT548pnPZN+PH5fgFgH0znvCYcS7sG2cyWr84biFiGAa0trZCfn4+hMNhqKmpgaamJigooCpuJxIKhRxZZ9M0IRwOQ1VVFcjy2HbkLvjGNE2YMmWK457xUlzNfgFg34wHPGac6RcA9o1TfTNWvzhua0aW5aGVlPRhqN2CggJHNfZIcGKdCwsLL+v8C74JhQZ/0uXEZ8yGE+t8uX4BYN+MFzxmnFtn9o0z6zwWv7BYlWEYhmEY2+CFCMMwDMMwtqFs2LBhg92VuBSKosDq1atBVR23i3RRJmKdR8tEfMaJWOexMBGfcyLWebRMxGeciHUeCxPxOSdinS+G48SqDMMwDMN8dOCtGYZhGIZhbIMXIgzDMAzD2AYvRBiGYRiGsQ1eiDAMwzAMYxu8EGEYhmEYxjYcuxDZvHkz1NbWgtfrhcWLF8OOHTvsrtIQ27dvh9tuuw2qqqpAkiR45ZVX0P+bpgkbNmyAqqoq8Pl8sHr1ajhy5IhNtc097Btn4mS/ALBvnOqbj7JfANg3TsCRC5GXXnoJHnroIXjsscdg//79cMMNN8C6devg/PnzdlcNAACi0SgsWLAAnn76acv/f+KJJ2DTpk3w9NNPw969eyEYDMItt9wC4XD4Ctc097BvnInT/QLAvnGqbz6qfgFg3zgG04EsXbrUvP/++9Gx+vp6c/369TbV6OIAgPnyyy8PlQ3DMIPBoPmjH/1o6FgikTALCwvNn/zkJ3ZUMaewb5zJRPKLabJvnOqbj5JfTJN94xQc90YklUrBu+++C2vXrkXH165dC7t377apViOnsbER2tvbUf09Hg+sWrVqQtT/UrBvnMlE9wsA+8apXK1+AWDfOAnHLUS6u7tB13WorKxExysrK6G9vd2mWo2cC3WcqPW/FOwbZzLR/QLAvnEqV6tfANg3TsJxC5ELSJKEyqZpkmNOZqLX/1JM9Geb6PW/GFfDc10Nz2DFRH+uiV7/SzHRn22i1x/AgQuRsrIyUBSFrOg6OzvJys+JBINBAIAJW/9Lwb5xJhPdLwDsG6dytfoFgH3jJBy3EHG73bB48WLYsmULOr5lyxZYsWKFTbUaObW1tRAMBlH9U6kUbNu2bULU/1Kwb5zJRPcLAPvGqVytfgFg3zgJZcOGDRvsroRIQUEBfPvb34bq6mrwer3w+OOPw9atW+FnP/sZFBUV2V09iEQicPToUWhvb4dnn30Wli1bBj6fD1KpFBQVFYGu67Bx40aoq6sDXdfhkUcegZaWFnjuuefA4/HYXf3Lgn3jTJzuFwD2jVN981H1CwD7xjHY9XOdbDzzzDPm1KlTTbfbbS5atMjctm2b3VUaYuvWrSYAkL97773XNM3Bn1V997vfNYPBoOnxeMwbb7zRPHz4sL2VziHsG2fiZL+YJvvGqb75KPvFNNk3TkAyTdO8YqsehmEYhmGYYThOI8IwDMMwzEcHXogwDMMwDGMbvBBhGIZhGMY2eCHCMAzDMIxt8EKEYRiGYRjb4IUIwzAMwzC2wQsRhmEYhmFsgxciDMMwDMPYBi9EGIZhGIaxDV6IMAzDMAxjG7wQYRiGYRjGNv4/VPkJ7PFtd6EAAAAASUVORK5CYII=",
      "text/plain": [
       "PyPlot.Figure(PyObject <Figure size 640x480 with 5 Axes>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PyObject <matplotlib.image.AxesImage object at 0x148d49b50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pkg.add(\"ImageView\")\n",
    "using ImageView\n",
    "using PyPlot\n",
    "\n",
    "X = readdlm(\"nnmf-2429-by-361-face.txt\")\n",
    "img1 = X[1,:]\n",
    "img1 = reshape(img1, 19, 19)\n",
    "img2 = X[13,:]\n",
    "img2 = reshape(img2, 19, 19)\n",
    "img3 = X[35, :]\n",
    "img3 = reshape(img3, 19, 19)\n",
    "img4 = X[125, :]\n",
    "img4 = reshape(img4, 19, 19)\n",
    "img5 = X[130, :]\n",
    "img5 = reshape(img5, 19, 19)\n",
    "\n",
    "subplot(1, 5, 1)\n",
    "PyPlot.imshow(img1)\n",
    "subplot(1, 5, 2)\n",
    "PyPlot.imshow(img2)\n",
    "subplot(1, 5, 3)\n",
    "PyPlot.imshow(img3)\n",
    "subplot(1, 5, 4)\n",
    "PyPlot.imshow(img4)\n",
    "subplot(1, 5, 5)\n",
    "PyPlot.imshow(img5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have read in the `nnmf-2429-by-361-face.txt file` using the readdlm() function and displayed a five sample images in my notebook using the ImageView.jl and PyPlot.jl packages. Notice the different features of each persons face, picked up by the image! Each of the rows of the $\\mathbf{X}$ are the pixels for a different individuals face in the sample. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.3 Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.716634 seconds (25 allocations: 7.331 MiB)\n",
      "  3.569488 seconds (33 allocations: 7.972 MiB, 0.17% gc time)\n",
      "  5.875026 seconds (25 allocations: 8.614 MiB)\n",
      "  8.732550 seconds (25 allocations: 9.258 MiB)\n",
      " 13.128490 seconds (26 allocations: 9.903 MiB, 0.04% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([4.06515e-8 0.0239183 … 0.00502753 0.0308952; 2.06692e-5 0.0167692 … 0.00168436 0.0335739; … ; 0.0136536 0.0204076 … 8.933e-5 0.0451226; 0.0182157 0.00994188 … 5.39374e-6 0.000142989], [1.98839e-64 1.24767e-53 … 2.73192e-14 8.87992e-65; 5.00853e-27 2.38036e-26 … 2.00588e-32 4.48034e-61; … ; 3.60097e-15 2.70773e-15 … 3.86231e-22 2.41101e-44; 0.000249871 6.68716e-20 … 2.36259e-7 1.30468e-11])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V0 = readdlm(\"V0.txt\");\n",
    "W0 = readdlm(\"W0.txt\");\n",
    "# with rank 10 its blurrier than with rank 50 because we are capturing less information from the original X\n",
    "\n",
    "@time nnmf(X, 10, V = V0[:, 1:10], W = W0[1:10, :])\n",
    "@time nnmf(X, 20, V = V0[:, 1:20], W = W0[1:20, :])\n",
    "@time nnmf(X, 30, V = V0[:, 1:30], W = W0[1:30, :])\n",
    "@time nnmf(X, 40, V = V0[:, 1:40], W = W0[1:40, :])\n",
    "@time nnmf(X, 50, V = V0[:, 1:50], W = W0[1:50, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we use `@time` on our function for fitting NNMF on the MIT CBCL face data set at ranks $r=10, 20, 30, 40, 50$, with the first $r$ columns of `V0.txt` and the first $r$ rows of `W0.txt` and stopping criterion\n",
    "$$\n",
    "\t\\frac{|L^{(t+1)} - L^{(t)}|}{|L^{(t)}| + 1} \\le 10^{-4}.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, we check the benchmark to get a more robust estimate of the runtime and memory allocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  9.90 MiB\n",
       "  allocs estimate:  22\n",
       "  --------------\n",
       "  minimum time:     10.744 s (0.00% GC)\n",
       "  median time:      10.744 s (0.00% GC)\n",
       "  mean time:        10.744 s (0.00% GC)\n",
       "  maximum time:     10.744 s (0.00% GC)\n",
       "  --------------\n",
       "  samples:          1\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using BenchmarkTools\n",
    "@benchmark nnmf(X, 50, V = V0[:, 1:50], W = W0[1:50, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.4 Solution:\n",
    "\n",
    "For r = 50, we do not obtain the same objective value and (V, W) are not the same from that of Q1.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.0313329 0.00703249 … 0.0207635 3.10162e-18; 0.0205671 0.00641766 … 0.0238345 0.00213217; … ; 8.1961e-8 0.00815619 … 0.0229242 0.00478911; 0.0173447 0.00494082 … 0.0237537 0.0113963], [3.65108e-37 1.03949e-22 … 1.3592e-8 3.52385e-69; 4.74768e-40 3.51854e-17 … 1.40341e-12 1.17764e-55; … ; 9.74744e-41 1.25524e-33 … 4.29157e-18 1.80434e-40; 2.56267e-22 1.2632e-18 … 20.8062 17.1294])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V_50, W_50 = nnmf(X, 50, V = V0[:, 1:50], W = W0[1:50, :])\n",
    "V_r, W_r = nnmf(X, 50) #with random starting points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L_50 = abs2(vecnorm(X .- V_50 * W_50, 2)) = 4430.201581697289\n",
      "L_random = abs2(vecnorm(X .- V_r * W_r, 2)) = 4388.971390067497\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4388.971390067497"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@show L_50 = abs2(vecnorm((X .- (V_50 * W_50)), 2))\n",
    "@show L_random = abs2(vecnorm((X .- (V_r * W_r)), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the squared Frobenius norms differ in `L_50` vs. `L_random`. Since the function is not a convex problem, indicating one global minima, when we optimize it from different starting points we may get different local minimums."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.5 Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_50 == V_1 = false\n",
      "W_50 == W_1 = false\n",
      "L_one = abs2(vecnorm(X .- V_1 * W_1, 2)) = 25297.01651108185\n",
      "L_50 = abs2(vecnorm(X .- V_50 * W_50, 2)) = 4430.201581697289\n"
     ]
    }
   ],
   "source": [
    "V_1, W_1 = nnmf(X, 50, V = ones(2429, 50), W = ones(50, 361))\n",
    "\n",
    "@show V_50 == V_1\n",
    "@show W_50 == W_1\n",
    "\n",
    "VW_1 = V_1 * W_1 # like our new X for initial values 1\n",
    "VW_50 = V_50 * W_50 # X = VW with first 50 columns and 50 rows \n",
    "\n",
    "@show L_one = abs2(vecnorm((X .- (V_1 * W_1)), 2))\n",
    "@show L_50 = abs2(vecnorm((X .- (V_50 * W_50)), 2));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the same  r = 50, initializing the algorithm from matrices of all ones, we do not obtain the same objective value or values of V and W. \n",
    "\n",
    "We check using the function `nnmfOneDemo`, which is essentially the same as the function nnmf but it only outputs how many iterations it takes for the function to converge. I created a separate function so the runtime and memory allocation of nnmf would not be altered. It shows that the function breaks out of the iteration loop when `i = 3`, indicating that it takes 2 updates of V and W for the stopping criteria to be met: \n",
    "\n",
    "$$\n",
    "\t\\frac{|L^{(t+1)} - L^{(t)}|}{|L^{(t)}| + 1} \\le 10^{-4}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nnmfOneDemo (generic function with 1 method)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using for loop\n",
    "function nnmfOneDemo(\n",
    "        X::Matrix{T},\n",
    "        r::Integer;\n",
    "        maxiter::Integer=1000, \n",
    "        tol::Number=1e-4,\n",
    "        V::Matrix{T}=rand(T, size(X, 1), r),\n",
    "        W::Matrix{T}=rand(T, r, size(X, 2))\n",
    "        ) where T <: AbstractFloat\n",
    "    #implementation\n",
    "    m, n = size(X)\n",
    "    A = zeros(X)\n",
    "    MR_1 = zeros(m, r)\n",
    "    MR_2 = zeros(m, r)\n",
    "    RR = zeros(r, r)\n",
    "    RN_1 = zeros(r, n)\n",
    "    RN_2 = zeros(r, n)\n",
    "    A_mul_B!(A, V, W)\n",
    "    A .= X .- A\n",
    "    l_last = abs2(vecnorm(A, 2))\n",
    "\n",
    "    for i in 1:maxiter\n",
    "        A_mul_Bt!(MR_1, X, W)\n",
    "        BLAS.syrk!('U', 'N', 1.0, W, 0.0, RR)\n",
    "        V .= V .* MR_1 ./ BLAS.symm!('R', 'U', 1.0, RR, V, 0.0, MR_2)\n",
    "\n",
    "        At_mul_B!(RN_1, V, X)\n",
    "        BLAS.syrk!('U', 'T', 1.0, V, 0.0, RR)\n",
    "        W .= W .* RN_1 ./ BLAS.symm!('L', 'U', 1.0, RR, W, 0.0, RN_2)\n",
    "\n",
    "        A_mul_B!(A, V, W)\n",
    "        A .= X .- A\n",
    "        l_new = abs2(vecnorm(A, 2))\n",
    "        if (abs(l_new - l_last) / (abs(l_last) + 1)) <= tol\n",
    "            println(i)\n",
    "            break\n",
    "        end\n",
    "        l_last = l_new\n",
    "    end\n",
    "    \n",
    "    return V, W\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.00547494 0.00547494 … 0.00547494 0.00547494; 0.00544131 0.00544131 … 0.00544131 0.00544131; … ; 0.00570319 0.00570319 … 0.00570319 0.00570319; 0.00560599 0.00560599 … 0.00560599 0.00560599], [0.369943 0.460643 … 0.5581 0.425542; 0.369943 0.460643 … 0.5581 0.425542; … ; 0.369943 0.460643 … 0.5581 0.425542; 0.369943 0.460643 … 0.5581 0.425542])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnmfOneDemo(X, 50, V =  V = ones(2429, 50), W = ones(50, 361))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we compare the images of individuals in the rows of VW_1 and VW_50. \n",
    "<br>\n",
    "We notice that VW_1 is the mean of X, and each row has some variation of the average American face in our sample. On the other hand, we see that VW_50 has different individuals in each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "PyPlot.Figure(PyObject <Figure size 640x480 with 4 Axes>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PyObject <matplotlib.image.AxesImage object at 0x137070290>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subplot(1, 4, 1)\n",
    "PyPlot.imshow(reshape(VW_1[1, :], 19, 19))\n",
    "subplot(1, 4, 2)\n",
    "PyPlot.imshow(reshape(VW_50[1, :], 19, 19))\n",
    "subplot(1, 4, 3)\n",
    "PyPlot.imshow(reshape(VW_1[60, :], 19, 19))\n",
    "subplot(1, 4, 4)\n",
    "PyPlot.imshow(reshape(VW_50[60, :], 19, 19))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we prove that with initial values of 1's for V and W, the function `nnmf` takes 2 updates of $\\mathbf{V}$ and $\\mathbf{W}$ for $\\mathbf{VW}$ to converge to the mean of the original matrix $\\mathbf{X}$. \n",
    "\n",
    "Consider minimization of the squared Frobenius norm\n",
    "$$\n",
    "\tL(\\mathbf{V}, \\mathbf{W}) = \\|\\mathbf{X} - \\mathbf{V} \\mathbf{W}\\|_{\\text{F}}^2 = \\sum_i \\sum_j \\left(x_{ij} - \\sum_k v_{ik} w_{kj} \\right)^2, \\quad v_{ik} \\ge 0, w_{kj} \\ge 0,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we give the initial values of ones, it converges in 2 steps, then the third iteration doesn't change anything thus breaks the loop.\n",
    "\n",
    "Note that when we plot the rows of the VW_1, we only get one face. That is, each row of VW_1 contains data which maps to the average American face thats in our original dataset X. \n",
    "\n",
    "Below, we show mathematically, that after two iterations $\\mathbf{X - V_2W_2}$ is the mean centered version of the original X matix:\n",
    "\n",
    "$\\mathbf{PROOF:}$\n",
    ">Initializing the values of V and W, we have:\n",
    "$$\\mathbf{V} = \\mathbf{1_m}\\mathbf{1_r}^{T}$$ and $$\\mathbf{W} = \\mathbf{1_r}\\mathbf{1_n}^{T}$$\n",
    ">and the following updates for V and W:\n",
    "$$\\mathbf{V} = \\mathbf{V} .* \\mathbf{X}\\mathbf{W}^{T} ./ (\\mathbf{VW{W}^T})$$\n",
    "$$\\mathbf{W} = \\mathbf{W} .* \\mathbf{V}^{T}\\mathbf{X} ./ (\\mathbf{{V}^{T}VW})$$\n",
    "<br>\n",
    "\n",
    "1V) First iteration of V:\n",
    ">We start with the numerator of V, $\\mathbf{X}\\mathbf{W}^{T}$:\n",
    "$$\\mathbf{X}\\mathbf{W}^{T} = \\mathbf{X}\\mathbf{1_n}\\mathbf{1_r}^{T} = \\mathbf{1_m}\\mathbf{\\sum_{j=1}^n {x_{ij}}}\\mathbf{1_r}^{T}, i \\in [1, m]$$ where i indicates the ith row of the original X matrix, which has m rows in total.\n",
    "<br>\n",
    ">Now making note of the fact that each image (row in original X) is scaled to have mean and standard deviation 0.25, we note that $\\sum_{i=1}^n {x_{ij}} = 0.25(n),$ thus we have:\n",
    "$$\\mathbf{1_m}0.25(n)\\mathbf{1_r}^{T} = 0.25(n)\\mathbf{1_m}\\mathbf{1_r}^{T}, i \\in [1, m]$$\n",
    "<br>\n",
    ">Now working on the denominator of V, $\\mathbf{VW{W}^T}$:\n",
    "$$\\mathbf{VW{W}^T} = \\mathbf{1_m}\\mathbf{1_r}^{T}(\\mathbf{1_r}\\mathbf{1_n}^{T})(\\mathbf{1_n}\\mathbf{1_r}^{T})$$\n",
    "$$ = \\mathbf{1_m}(rn)\\mathbf{1_r}^{T}$$\n",
    "$$ = nr\\mathbf{1_m}\\mathbf{1_r}^{T}$$\n",
    "<br>\n",
    ">Now we can update our initial value of V (matrix of ones) as follows:\n",
    "$$\\mathbf{V_1} = \\mathbf{1_m}\\mathbf{1_r}^{T} .* 0.25(n)\\mathbf{1_m}\\mathbf{1_r}^{T} ./ (nr\\mathbf{1_m}\\mathbf{1_r}^{T})$$\n",
    "$$= \\frac{0.25}{r}\\mathbf{1_m}\\mathbf{1_r}^{T}$$\n",
    "<br>\n",
    "\n",
    "1W) First iteration of W:\n",
    "\n",
    ">We start with the numerator of W, $\\mathbf{V}^{T}\\mathbf{X}$, using $\\mathbf{V_1}$ from above:\n",
    "$$\\mathbf{V}^{T}\\mathbf{X} = (\\frac{0.25}{r}\\mathbf{1_m}\\mathbf{1_r}^{T})\\mathbf{X} = \\mathbf{1_r}m(0.25)\\mathbf{1_n}^{T} = m(0.25)\\mathbf{1_r}\\mathbf{1_n}^{T}$$\n",
    "<br>\n",
    ">Now working on the denominator of V, $\\mathbf{{V}^{T}VW}$:\n",
    "$$\\mathbf{{V}^{T}VW} = ({\\frac{0.25}{r}})^{2}(\\mathbf{1_r}\\mathbf{1_m}^{T})\\mathbf{1_m}\\mathbf{1_r}^{T}(\\mathbf{1_r}\\mathbf{1_n}^{T})$$\n",
    "> Since $\\mathbf{1_m}^{T}\\mathbf{1_m} = m $ and $\\mathbf{1_r}^{T}\\mathbf{1_r} = r,$ we have:\n",
    "$$\\mathbf{{V}^{T}VW} = ({\\frac{0.25}{r}})^{2}(\\mathbf{1_r}(m)(r)\\mathbf{1_n}^{T})$$\n",
    "<br>\n",
    "$$ = ({\\frac{0.25}{r}})^{2}mr(\\mathbf{1_r}\\mathbf{1_n}^{T}) $$\n",
    "<br>\n",
    "$$ = ({\\frac{0.25^{2}}{r}})m(\\mathbf{1_r}\\mathbf{1_n}^{T}) $$\n",
    "<br>\n",
    ">Now we can update our initial value of V (matrix of ones) as follows:\n",
    "$$\\mathbf{W_1} = \\mathbf{1_r}\\mathbf{1_n}^{T} .* m(0.25)\\mathbf{1_r}\\mathbf{1_n}^{T} ./ ({\\frac{0.25^{2}}{r}})m(\\mathbf{1_r}\\mathbf{1_n}^{T})$$\n",
    "$$= \\frac{mr}{0.25}\\mathbf{1_r}\\mathbf{1_n}^{T}$$\n",
    "<br>\n",
    "\n",
    "2V) Similarly, we do the Second iteration of V and W using the values of V_1 and W_1 as the new starting points.\n",
    "\n",
    ">We start with the numerator of V_2, $\\mathbf{X}\\mathbf{W}^{T}$:\n",
    "$$\\mathbf{X}\\mathbf{W}^{T} = \\frac{mr}{0.25}\\mathbf{X}\\mathbf{1_r}\\mathbf{1_n}^{T}$$ <br>\n",
    "$$ = mrn\\mathbf{1_m}\\mathbf{1_r}^{T}$$\n",
    "<br>\n",
    ">Now working on the denominator of V_2, $\\mathbf{VW{W}^T}$:\n",
    "$$\\mathbf{VW{W}^T} = \\frac{0.25}{r}\\mathbf{1_m}\\mathbf{1_r}^{T}(\\frac{mr}{0.25})^{2}\\mathbf{1_r}\\mathbf{1_n}^{T}\\mathbf{1_n}\\mathbf{1_r}^{T}$$<br>\n",
    "$$ = \\mathbf{1_m}(rn)\\mathbf{1_r}^{T}$$\n",
    "$$ = \\frac{m^{2}r^{2}n}{0.25}\\mathbf{1_m}\\mathbf{1_r}^{T}$$\n",
    "<br>\n",
    ">Now we can update our value of V_1 with V_2 as follows:\n",
    "$$\\mathbf{V_2} = \\frac{0.25}{r}\\mathbf{1_m}\\mathbf{1_r}^{T} .* mrn\\mathbf{1_m}\\mathbf{1_r}^{T} ./ (\\frac{m^{2}r^{2}n}{0.25}\\mathbf{1_m}\\mathbf{1_r}^{T})$$\n",
    "$$= \\frac{0.25^{2}}{mr^{2}}\\mathbf{1_m}\\mathbf{1_r}^{T}$$\n",
    "<br>\n",
    "\n",
    "\n",
    "2W) Second iteration of W:\n",
    "\n",
    ">We start with the numerator of W_2, $\\mathbf{V}^{T}\\mathbf{X}$, using $\\mathbf{V_2}$ from above:\n",
    "$$\\mathbf{V}^{T}\\mathbf{X} = (\\frac{0.25^{2}}{mr^{2}}\\mathbf{1_r}\\mathbf{1_m}^{T})\\mathbf{X} = (\\frac{0.25^{2}}{mr^{2}}\\mathbf{1_r}(0.25m)\\mathbf{1_n}^{T}) = \\frac{0.25^{3}}{r^{2}}\\mathbf{1_r}\\mathbf{1_n}^{T}$$\n",
    "<br>\n",
    ">Now working on the denominator of W_2, $\\mathbf{{V_1}^{T}V_1W_1}$:\n",
    "$$\\mathbf{{V_1}^{T}V_1W_1} = ({\\frac{0.25^{4}}{m^{2}r4}})(\\mathbf{1_r}\\mathbf{1_m}^{T})(\\mathbf{1_m}\\mathbf{1_r}^{T})(\\frac{mr}{0.25})\\mathbf{1_r}\\mathbf{1_n}^{T}$$<br>\n",
    "$$ = (\\frac{mr}{0.25})\\mathbf{1_r}\\mathbf{1_n}^{T}$$\n",
    "<br>\n",
    ">Now we can update our value of W_2 as follows:\n",
    "$$\\mathbf{W_2} = \\frac{mr}{0.25}\\mathbf{1_r}\\mathbf{1_n}^{T} .* \\frac{0.25^{3}}{r^{2}}\\mathbf{1_r}\\mathbf{1_n}^{T} ./ (\\frac{mr}{0.25})\\mathbf{1_r}\\mathbf{1_n}^{T})$$<br>\n",
    "$$= \\frac{mr}{0.25}\\mathbf{1_r}\\mathbf{1_n}^{T}$$\n",
    "<br>\n",
    "\n",
    "**Calculating X - VW after 2 iterations:**\n",
    "<br>\n",
    ">First we will calculate the product $\\mathbf{V_2} * \\mathbf{W_2}:$\n",
    "$$\\mathbf{V_2W_2} = \\frac{0.25^{2}}{mr^{2}}\\mathbf{1_m}\\mathbf{1_r}^{T}\\frac{mr}{0.25}\\mathbf{1_r}\\mathbf{1_n}^{T}$$<br>\n",
    "$$ = \\frac{0.25}{r}\\mathbf{1_m}\\mathbf{1_r}^{T}\\mathbf{1_r}\\mathbf{1_n}^{T}$$<br>\n",
    "$$ = \\frac{0.25}{r}(r)\\mathbf{1_m}\\mathbf{1_n}^{T}$$ <br>\n",
    "$$ = 0.25\\mathbf{1_m}\\mathbf{1_n}^{T}$$\n",
    "<br>\n",
    ">Then, for $\\mathbf{X}$ is a mxn matrix we will calculate the quanitity $\\mathbf{X - V_2W_2}:$<br>\n",
    "$$\\mathbf{X} .- 0.25\\mathbf{1_m}\\mathbf{1_n}^{T}$$<br>\n",
    ">Thus we note that this is the mean centered version of the original X matrix after two iterations of updating the values of V and W from initial matrices of all ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.6 Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "PyPlot.Figure(PyObject <Figure size 640x480 with 4 Axes>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "V, W = nnmf(X, 50, V = V0[:, 1:50], W = W0[1:50, :])\n",
    "\n",
    "W_img1 = W[1, :]\n",
    "W_img1 = reshape(W_img1, 19, 19)\n",
    "\n",
    "W_img2 = W[2, :]\n",
    "W_img2 = reshape(W_img2, 19, 19)\n",
    "\n",
    "W_img5 = W[9, :]\n",
    "W_img5 = reshape(W_img5, 19, 19)\n",
    "\n",
    "W_img10 = W[10, :]\n",
    "W_img10 = reshape(W_img10, 19, 19)\n",
    "\n",
    "#VW = V*W\n",
    "subplot(1, 4, 1)\n",
    "PyPlot.imshow(W_img1)\n",
    "subplot(1, 4, 2)\n",
    "PyPlot.imshow(W_img2)\n",
    "subplot(1, 4, 3)\n",
    "PyPlot.imshow(W_img5)\n",
    "subplot(1, 4, 4)\n",
    "PyPlot.imshow(W_img10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we plot the basis images (rows of  W) at rank  r = 50. \n",
    "\n",
    "Note that from the first row, we see a glimpse of the image of the upper lip of an individual's face.\n",
    "From the second row, we see what appears to be the right cheekbone of an individual's face. \n",
    "From the ninth row, we see what appears to be the forehead of an individual's face. \n",
    "From the tenth row, we see what appears to be the nose bridge and right cheekbone of an individual's face. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Linear Mixed Models\n",
    "\n",
    "Consider a linear mixed effects model\n",
    "$$\n",
    "\ty_i = \\mathbf{x}_i^T \\beta + \\mathbf{z}_i^T \\gamma + \\epsilon_i, \\quad i=1,\\ldots,n,\n",
    "$$\n",
    "where $\\epsilon_i$ are independent normal errors $N(0,\\sigma_0^2)$, $\\beta \\in \\mathbb{R}^p$ are fixed effects, and $\\gamma \\in \\mathbb{R}^q$ are random effects assumed to be $N(\\mathbf{0}_q, \\sigma_1^2 \\mathbf{I}_q$) independent of $\\epsilon_i$. \n",
    "\n",
    "0. Show that \n",
    "$$\n",
    "    \\mathbf{y} \\sim N \\left( \\mathbf{X} \\beta, \\sigma_0^2 \\mathbf{I}_n + \\sigma_1^2 \\mathbf{Z} \\mathbf{Z}^T \\right),\n",
    "$$\n",
    "where $\\mathbf{y} = (y_1, \\ldots, y_n)^T \\in \\mathbb{R}^n$, $\\mathbf{X} = (\\mathbf{x}_1, \\ldots, \\mathbf{x}_n)^T \\in \\mathbb{R}^{n \\times p}$, and $\\mathbf{Z} = (\\mathbf{z}_1, \\ldots, \\mathbf{z}_n)^T \\in \\mathbb{R}^{n \\times q}$. \n",
    "\n",
    "0. Write a function, with interface \n",
    "    ```julia\n",
    "    logpdf_mvn(y::Vector, Z::Matrix, σ0::Number, σ1::Number),\n",
    "    ```\n",
    "that evaluates the log-density of a multivariate normal with mean $\\mathbf{0}$ and covariance $\\sigma_0^2 \\mathbf{I} + \\sigma_1^2 \\mathbf{Z} \\mathbf{Z}^T$ at $\\mathbf{y}$. Make your code efficient in the $n \\gg q$ case. \n",
    "\n",
    "0. Compare your result (both accuracy and timing) to the [Distributions.jl](http://distributionsjl.readthedocs.io/en/latest/multivariate.html#multivariate-normal-distribution) package using following data.  \n",
    "    ```julia\n",
    "    using BenchmarkTools, Distributions\n",
    "\n",
    "    srand(280)\n",
    "    n, q = 2000, 10\n",
    "    Z = randn(n, q)\n",
    "    σ0, σ1 = 0.5, 2.0\n",
    "    Σ = σ1^2 * Z * Z.' + σ0^2 * I\n",
    "    mvn = MvNormal(Σ) # MVN(0, Σ)\n",
    "    y = rand(mvn) # generate one instance from MNV(0, Σ)\n",
    "\n",
    "    # check you answer matches that from Distributions.jl\n",
    "    @show logpdf_mvn(y, Z, σ0, σ1)\n",
    "    @show logpdf(mvn, y)\n",
    "\n",
    "    # benchmark\n",
    "    @benchmark logpdf_mvn(y, Z, σ0, σ1)\n",
    "    @benchmark logpdf(mvn, y)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2.1 Solution:\n",
    "\n",
    "Below I will show that:\n",
    "$$\n",
    "    \\mathbf{y} \\sim N \\left( \\mathbf{X} \\beta, \\sigma_0^2 \\mathbf{I}_n + \\sigma_1^2 \\mathbf{Z} \\mathbf{Z}^T \\right),\n",
    "$$\n",
    "where $\\mathbf{y} = (y_1, \\ldots, y_n)^T \\in \\mathbb{R}^n$, $\\mathbf{X} = (\\mathbf{x}_1, \\ldots, \\mathbf{x}_n)^T \\in \\mathbb{R}^{n \\times p}$, and $\\mathbf{Z} = (\\mathbf{z}_1, \\ldots, \\mathbf{z}_n)^T \\in \\mathbb{R}^{n \\times q}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$${f(\\mathbf{y}) = \\frac1{sqrt(2\\pi))^p|\\mathbf{\\Sigma}|^{1/2}}} * e^{-(\\mathbf{y}-\\mathbf{\\mu})^{T}\\mathbf{\\Sigma}^{-1}(\\mathbf{y}-\\mu)/2}$$ \n",
    "<br>\n",
    ">Take the log of both sides to get the log pdf:\n",
    "\n",
    "$$log(f(\\mathbf{y})) =  \\frac{-p}{2}log(2\\pi) - \\frac{-1}{2}log|\\mathbf{\\Sigma}| - \\frac{[(\\mathbf{y}-\\mathbf{\\mu})^T\\mathbf{\\Sigma}^{-1}(\\mathbf{y}-\\mathbf{\\mu})]}{2}$$\n",
    "<br>\n",
    "\n",
    ">Now, we use the **Woodbury formula**:\n",
    "$$(\\mathbf{A} + \\mathbf{U} \\mathbf{V}^T)^{-1} = \\mathbf{A}^{-1} - \\mathbf{A}^{-1} \\mathbf{U} (\\mathbf{I}_m + \\mathbf{V}^T \\mathbf{A}^{-1} \\mathbf{U})^{-1} \\mathbf{V}^T \\mathbf{A}^{-1},\n",
    "$$\n",
    "where $\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$ is nonsingular, $\\mathbf{U}, \\mathbf{V} \\in \\mathbb{R}^{n \\times m}$, and $\\mathbf{I}_m$ is the $m \\times m$ identity matrix.\n",
    "\n",
    ">Let $\\mathbf{A} = \\sigma_0^{2}\\mathbf{I}$ and $\\mathbf{U} = \\mathbf{V} = \\sigma_1\\mathbf{Z}$\n",
    "<br>\n",
    "Using the Woodbury Formula and properties of determinants of block matrices, we can plug in $\\mathbf{|\\Sigma|}$ and $\\mathbf{\\Sigma^{-1}}$ as follows into the logpdf:\n",
    "<br>\n",
    "\n",
    "$$\\mathbf{\\Sigma^{-1}} = ({\\sigma_0^{2}}\\mathbf{I} + \\sigma_1^{2}\\mathbf{Z{Z}^{T}})^{-1}\\mathbf{Z^{T}} = \\sigma_0^{-2}\\mathbf{I} - \\sigma_0^{-4}\\sigma_1^{2}*\\mathbf{Z}* (\\mathbf{I} + \\sigma_0^{-2}*\\sigma_1^{2}\\mathbf{Z^{T}Z})\\mathbf{Z^{T}}$$\n",
    "<br>\n",
    ">Now making use of the property of the determinants of block matrices below:\n",
    "$$\\text{det}(\\mathbf{A} + \\mathbf{U} \\mathbf{V}^T) = \\text{det}(\\mathbf{A}) \\text{det}(\\mathbf{I}_m + \\mathbf{V}^T \\mathbf{A}^{-1} \\mathbf{U}).\n",
    "$$\n",
    ">We get:\n",
    "$$\\mathbf{|\\Sigma|} = det({\\sigma_0^{2}}\\mathbf{I} + \\sigma_1^{2}\\mathbf{Z{Z}^{T}}) = det({\\sigma_0^{2}}\\mathbf{I}) * det(\\mathbf{I} + \\sigma_0^{-2}\\sigma_1^{2}\\mathbf{Z^{T}Z}) = {\\sigma_0^{2n}} * (\\mathbf{I} + \\sigma_0^{-2}\\sigma_1^{2}\\mathbf{Z^{T}Z})$$\n",
    "\n",
    "<br>\n",
    "$$log(f(\\mathbf{y})) =  \\frac{-p}{2}log(2\\pi) - \\frac{-1}{2}log|\\mathbf{\\Sigma}| - \\frac{[(\\mathbf{y}-\\mathbf{\\mu})^T\\mathbf{\\Sigma}^{-1}(\\mathbf{y}-\\mathbf{\\mu})]}{2}$$\n",
    "<br>\n",
    "\n",
    ">where we note that: log|$\\mathbf{\\Sigma}|$ = 2 * n * log(σ0) + logdet($\\mathbf{I}$ + $\\sigma_0^{-2}$*$\\sigma_1^{2}\\mathbf{Z^{T}Z}$))\n",
    "<br>\n",
    "\n",
    "$$log(f(\\mathbf{y})) =  \\frac{-p}{2}log(2\\pi) - \\frac{-1}{2}*(2 * n * log(σ0) + logdet(\\mathbf{I} + $\\sigma_0^{-2}*\\sigma_1^{2}\\mathbf{Z^{T}Z})) - \\frac{[(\\mathbf{y}-\\mathbf{\\mu})^T\\mathbf{\\Sigma}^{-1}(\\mathbf{y}-\\mathbf{\\mu})]}{2}$$\n",
    "<br>\n",
    "\n",
    ">Since we are given that $\\mathbf{\\mu}$ = 0, we can rewrite the log-pdf as:\n",
    "\n",
    "$$log(f(\\mathbf{y})) =  \\frac{-p}{2}log(2\\pi) - \\frac{-1}{2}*(2 * n * log(σ0) + logdet(\\mathbf{I} + $\\sigma_0^{-2}*\\sigma_1^{2}\\mathbf{Z^{T}Z})) - \\frac{[(\\mathbf{y})^T\\mathbf{\\Sigma}^{-1}(\\mathbf{y})]}{2}$$\n",
    "<br>\n",
    "\n",
    ">Substituting in $\\mathbf{\\Sigma^{-1}}$ we have:\n",
    "\n",
    "$$log(f(\\mathbf{y})) =  \\frac{-p}{2}log(2\\pi) - \\frac{-1}{2}*(2 * n * log(σ0) + logdet(\\mathbf{I} + \\sigma_0^{-2}*\\sigma_1^{2}\\mathbf{Z^{T}Z})) - \\frac{[(\\mathbf{y})^T(\\sigma_0^{-2}\\mathbf{I} - \\sigma_0^{-4}*\\sigma_1^{2}*\\mathbf{Z}(\\mathbf{I} + \\sigma_0^{-2}*\\sigma_1^{2}\\mathbf{Z^{T}Z}))(\\mathbf{y})]}{2}$$\n",
    "<br>\n",
    "\n",
    ">Now distributing out the $y$ and $y^T$ we get:\n",
    "\n",
    "$$log(f(\\mathbf{y})) =  \\frac{-p}{2}log(2\\pi) - \\frac{-1}{2}*(2 * n * log(σ0) + logdet(\\mathbf{I} + \\sigma_0^{-2}*\\sigma_1^{2}\\mathbf{Z^{T}Z})) - \\frac{(\\mathbf{y})^T(\\sigma_0^{-2})\\mathbf{y}}{2} + (\\frac{\\sigma_1}{\\sigma_0^{2}}\\mathbf{{y}^{T}Z})(\\mathbf{I} + \\sigma_0^{-2}*\\sigma_1^{2}\\mathbf{Z^{T}Z})(\\mathbf{{Z}^{T}}\\mathbf{y}\\frac{\\sigma_1}{\\sigma_0^{2}})$$\n",
    "\n",
    ">Thus, we write the function below, utilizing symmetric and positive definite structure of $\\mathbf{\\Sigma} = (\\mathbf{I} + \\sigma_0^{-2}*\\sigma_1^{2}\\mathbf{Z^{T}Z})$ through Cholesky Decomposition. We then can use this decomposition to speed up efficiency and reduce our benchmarking run time, when computing the determinant or solving the linear system of equations in the last term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Now we we will show that the variance evaluates the variance of the log-density of a multivariate normal with mean 0 and and covariance matrix $\\mathbf{\\Sigma} = (\\mathbf{I} + \\sigma_0^{-2}*\\sigma_1^{2}\\mathbf{Z^{T}Z})$<br>\n",
    "<br>\n",
    ">First we start by showing that the mean of $\\mathbf{y}$ is $\\mathbf{0}$:\n",
    "$$\\mathbf{y} = \\mathbf{X} \\mathbf{\\beta} + \\mathbf{Z}^T \\mathbf{\\gamma} + \\mathbf{\\epsilon}$$\n",
    "<br>\n",
    "$$E[\\mathbf{y}] = E[\\mathbf{X} \\beta + \\mathbf{Z}^T \\mathbf{\\gamma} + \\mathbf{\\epsilon}]$$\n",
    "<br>\n",
    "$$E[\\mathbf{y}] = E[\\mathbf{X} \\beta] + E[\\mathbf{Z}^T \\mathbf{\\gamma}] + E[\\mathbf{\\epsilon}]$$\n",
    "<br>\n",
    "$$E[\\mathbf{y}] = E[\\mathbf{X}]\\mathbf{\\beta} + \\mathbf{Z}^TE[\\mathbf{\\gamma}] + E[\\mathbf{\\epsilon}]$$\n",
    "<br> \n",
    ">Recall that we are given that $\\epsilon_i$ are independent normal errors $N(\\mathbf{0},\\sigma_0^2)$, $\\beta \\in \\mathbb{R}^p$ are fixed effects, and $\\mathbf{\\gamma} \\in \\mathbb{R}^q$ are random effects assumed to be $N(\\mathbf{0}_q, \\sigma_1^2 \\mathbf{I}_q$) independent of $\\epsilon_i$. Then plugging in $E[\\mathbf{\\gamma}] = \\mathbf{0}$ and $E[\\mathbf{\\epsilon}] = \\mathbf{0}$, we get:\n",
    "<br>\n",
    "$$E[\\mathbf{y}] = E[\\mathbf{X}]\\mathbf{\\beta} + \\mathbf{Z}^T[\\mathbf{0}] + [\\mathbf{0}]$$\n",
    ">And then we make note of the fact that X is a matrix of fixed effects, so we get:\n",
    "$$E[\\mathbf{y}] = \\mathbf{X}\\mathbf{\\beta}$$\n",
    "<br>\n",
    "\n",
    ">Now we we will show that the covariance of y evaluates to $\\mathbf{\\Sigma} = (\\mathbf{I} + \\sigma_0^{-2}*\\sigma_1^{2}\\mathbf{Z^{T}Z})$\n",
    "<br>\n",
    "$$Var(\\mathbf{y}) = Var(\\mathbf{X} \\beta + \\mathbf{Z}^T \\mathbf{\\gamma} + \\mathbf{\\epsilon})$$\n",
    "<br>\n",
    "$$Var(\\mathbf{y}) = Var(\\mathbf{X} \\beta) + Var(\\mathbf{Z}^T \\mathbf{\\gamma}) + Var(\\mathbf{\\epsilon})$$\n",
    "<br>\n",
    ">Now, making note of the fact that $Var(\\mathbf{X}\\mathbf{\\beta}) = 0$, since $\\mathbf{\\beta}$ and $\\mathbf{X}$ are fixed constants, we get:\n",
    "$$Var(\\mathbf{y}) = 0 + \\mathbf{Z}^TVar(\\mathbf{\\gamma})\\mathbf{Z} + Var(\\mathbf{\\epsilon})$$\n",
    "<br>\n",
    ">Now plugging in $Var(\\mathbf{\\gamma}) = \\sigma_1^2 \\mathbf{I}_q$ and $Var(\\mathbf{\\epsilon}) = \\sigma_0^2$ we get:\n",
    "<br>\n",
    "$$Var(\\mathbf{y}) = \\mathbf{Z}^T(\\sigma_1^2 \\mathbf{I}_q)\\mathbf{Z} + \\sigma_0^2(\\mathbf{I})$$\n",
    "<br>\n",
    "$$Var(\\mathbf{y}) = \\mathbf{I} + \\sigma_0^{-2}*\\sigma_1^{2}\\mathbf{Z^{T}Z}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2.2\n",
    "\n",
    "Below I have written a function, made efficient for the $n \\gg q$ case. \n",
    "    ```julia\n",
    "    logpdf_mvn(y::Vector, Z::Matrix, σ0::Number, σ1::Number),\n",
    "    ```\n",
    "that evaluates the log-density of a multivariate normal with mean $\\mathbf{0}$ and covariance $\\sigma_0^2 \\mathbf{I} + \\sigma_1^2 \\mathbf{Z} \\mathbf{Z}^T$ at $\\mathbf{y}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logpdf_mvn (generic function with 1 method)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# better efficiency\n",
    "function logpdf_mvn(y::Vector, Z::Matrix, σ0::Number, σ1::Number)\n",
    "    n = length(y)\n",
    "    Σchol = cholfact!(σ1^2/σ0^2 * (Z' * Z) + I)\n",
    "    logdetΣchol = 2 * n * log(σ0) + logdet(Σchol)\n",
    "    - (n//2) * log(2π) - (1//2) * logdetΣchol - (1//2) * (sum(abs2, y)/σ0^2 -\n",
    "        sum(abs2, Σchol[:L] \\ ((Z' * y) * (σ1/σ0^2))))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2.3 Solution:\n",
    "\n",
    "Below I compare the results by both accuracy and timing, to the `logpdf()` function in the Distributions.jl package using the given data.\n",
    "\n",
    "First, I check if we get the same value out from our function and the built in function, and we do! Using the given data as inputs, both functions return a value of -1571.573673465 with some minor floating point rounding margin between the two (which is negligable). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logpdf_mvn(y, Z, σ0, σ1) = -1571.5736734653365\n",
      "logpdf(mvn, y) = -1571.5736734654135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1571.5736734654135"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using BenchmarkTools, Distributions\n",
    "\n",
    "    srand(280)\n",
    "    n, q = 2000, 10\n",
    "    Z = randn(n, q)\n",
    "    σ0, σ1 = 0.5, 2.0\n",
    "    Σ = σ1^2 * Z * Z.' + σ0^2 * I\n",
    "    mvn = MvNormal(Σ) # MVN(0, Σ)\n",
    "    y = rand(mvn) # generate one instance from MNV(0, Σ)\n",
    "\n",
    "    # check you answer matches that from Distributions.jl\n",
    "@show logpdf_mvn(y, Z, σ0, σ1)\n",
    "@show logpdf(mvn, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we use the BenchmarkingTools.jl package to benchmark the two functions, and compare efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  4.17 KiB\n",
       "  allocs estimate:  16\n",
       "  --------------\n",
       "  minimum time:     37.784 μs (0.00% GC)\n",
       "  median time:      56.675 μs (0.00% GC)\n",
       "  mean time:        61.678 μs (0.81% GC)\n",
       "  maximum time:     3.099 ms (92.81% GC)\n",
       "  --------------\n",
       "  samples:          10000\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# benchmark\n",
    "@benchmark logpdf_mvn(y, Z, σ0, σ1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  15.78 KiB\n",
       "  allocs estimate:  3\n",
       "  --------------\n",
       "  minimum time:     3.922 ms (0.00% GC)\n",
       "  median time:      6.345 ms (0.00% GC)\n",
       "  mean time:        6.081 ms (0.00% GC)\n",
       "  maximum time:     10.068 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          819\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark logpdf(mvn, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory:\n",
    "\n",
    "Notice how my function implementation of the logpdf take on average 4.17 KiB of memory while the built in logpdf function implementation takes on average 15.78 KiB of memory.\n",
    "\n",
    "This indicates that our function allocates about 15.78/4.17 = 3.78 fold less memory than the built in function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timing:\n",
    "\n",
    "Notice how my function implementation of the logpdf takes a median of 56.675 μs while the built in logpdf function implementation takes a median of 6.345 ms to run.\n",
    "\n",
    "This indicates that our function is about 6.345/.056675 = 111.95 fold faster than the built in function! \n",
    "\n",
    "Small, fast and wicked cool~"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "87px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
