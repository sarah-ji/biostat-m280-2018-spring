{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biostat M280 Homework 3\n",
    "\n",
    "Sarah Ji\n",
    "\n",
    "**Due Friday, May 25 @ 11:59PM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1 - Big $n$ regression\n",
    "\n",
    "Those who took my _203B: Introduction to Data Science_ last quarter had a (painful) experience of wrangling an Apache Spark cluster to do linear regression on a dataset with more than 100 million observations. Now we learnt various methods for solving linear regression and should realize that, with right choice of algorithm, it is a problem that can be handled by any moderate computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1(1)\n",
    "\n",
    "Download the flight data from <http://stat-computing.org/dataexpo/2009/the-data.html>. For this exercise, we only need data from years 2003-2008. If you are using Mac or Linux, you can run the following Bash script, which downloads and unzips files for all years.\n",
    "```bash\n",
    "# Download flight data by year\n",
    "for i in {1987..2008}\n",
    "  do\n",
    "    echo \"$(date) $i Download\"\n",
    "    fnam=$i.csv.bz2\n",
    "    wget -O ./$fnam http://stat-computing.org/dataexpo/2009/$fnam\n",
    "    echo \"$(date) $i unzip\"\n",
    "    bzip2 -d ./$fnam\n",
    "  done\n",
    "\n",
    "# Download airline carrier data\n",
    "wget -O ./airlines.csv http://www.transtats.bts.gov/Download_Lookup.asp?Lookup=L_UNIQUE_CARRIERS\n",
    "\n",
    "# Download airports data\n",
    "wget -O ./airports.csv https://raw.githubusercontent.com/jpatokal/openflights/master/data/airports.dat\n",
    "```\n",
    "Find out how many data points in each year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1(1) Solution:\n",
    "\n",
    "Below, we use the `countlines()` function in Julia to see how many data points there are in each year. We find that there is a steady increase in the number of data points from years 2003-2007, but a sharp decrease in data points from 2007 to 2008. We suspect this drop in 2008 may be related to the national airport shutdowns following the 9/11 attacks this year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "countlines(\"allyears/2003.csv\") = 6488541\n",
      "countlines(\"allyears/2004.csv\") = 7129271\n",
      "countlines(\"allyears/2005.csv\") = 7140597\n",
      "countlines(\"allyears/2006.csv\") = 7141923\n",
      "countlines(\"allyears/2007.csv\") = 7453216\n",
      "countlines(\"allyears/2008.csv\") = 7009729\n"
     ]
    }
   ],
   "source": [
    "# how many data points\n",
    "@show countlines(\"allyears/2003.csv\")\n",
    "# how many data points\n",
    "@show countlines(\"allyears/2004.csv\")\n",
    "# how many data points\n",
    "@show countlines(\"allyears/2005.csv\")\n",
    "# how many data points\n",
    "@show countlines(\"allyears/2006.csv\")\n",
    "# how many data points\n",
    "@show countlines(\"allyears/2007.csv\")\n",
    "# how many data points\n",
    "@show countlines(\"allyears/2008.csv\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1(2) \n",
    "\n",
    "We are interested in how the time gain of a flight, defined as `DepDelay - ArrDelay`, depends on the distance traveled (`Distance`), departure delay (`DepDelay`), and carrier (`UniqueCarrier`). \n",
    "\n",
    "We want to fit a linear regression `Gain ~ 1 + Distance + DepDelay + UniqueCarrier` using data from 2003-2008. Note `UniqueCarrier` is a factor with 23 levels: \"9E\", \"AA\", \"AQ\", \"AS\", \"B6\", \"CO\", \"DH\", \"DL\", \"EV\", \"F9\", \"FL\", \"HA\", \"HP\", \"MQ\", \"NW\", \"OH\", \"OO\", \"TZ\", \"UA\", \"US\", \"WN\", \"XE\", and \"YV\". We use the dummy coding with \"9E\" as base level.\n",
    "\n",
    "Will the design matrix (in double precision) fit into the memory of you computer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1(2) Solution:\n",
    "\n",
    "First I checked the dimension of the design matrix we need for the regression. Since our model has an intercept, we have 5 columns and counting the number of rows in each year we have 42,363,271 rows. So our design matrix is a 42,363,271 by 5 matrix, and it can fit on the memory of my computer (but I prefer it didn't)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If each number is stored in double precicion, we need 8,629,998,000 bytes or 8.629998 GiB of memory to store this matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8629998000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculating the number of bytes this data will need\n",
    "41490375*26*8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144.322472 seconds (388.15 M allocations: 17.699 GiB, 3.65% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Table with 41490375 rows, 4 columns:\n",
       "DepDelay  ArrDelay  UniqueCarrier  Distance\n",
       "───────────────────────────────────────────\n",
       "-4        -1        \"UA\"           837\n",
       "-1        -3        \"UA\"           837\n",
       "29        23        \"UA\"           837\n",
       "-2        -9        \"UA\"           1835\n",
       "18        52        \"UA\"           1835\n",
       "-4        6         \"UA\"           1835\n",
       "-4        -8        \"UA\"           1835\n",
       "0         2         \"UA\"           1835\n",
       "-4        19        \"UA\"           1835\n",
       "3         4         \"UA\"           413\n",
       "-4        -23       \"UA\"           413\n",
       "-3        -19       \"UA\"           413\n",
       "⋮\n",
       "57        75        \"DL\"           481\n",
       "80        99        \"DL\"           689\n",
       "-2        15        \"DL\"           270\n",
       "-4        6         \"DL\"           425\n",
       "-3        16        \"DL\"           546\n",
       "-1        2         \"DL\"           215\n",
       "3         14        \"DL\"           533\n",
       "-1        -2        \"DL\"           874\n",
       "-5        0         \"DL\"           545\n",
       "11        9         \"DL\"           533\n",
       "7         -5        \"DL\"           874"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data from csv\n",
    "using JuliaDB\n",
    "@time yrtable = loadtable(\n",
    "    \"allyears\", \n",
    "    datacols = [\"DepDelay\", \"ArrDelay\", \"UniqueCarrier\", \"Distance\"])\n",
    "# drop rows with missing values\n",
    "yrtable = dropna(yrtable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we drop missing values, I count again how many bytes this design matrix will use. Even after dropping rows with missing values, we will use 8.62999696 GiB of memory.\n",
    "\n",
    "Below is the function that maps from variable names to X columns and generates the [X y] matrix. We will use this function to get our design matrix `xy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generate_xy (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mapping from variable names to X columns\n",
    "# carrier \"9E\" is used as base level\n",
    "const var2col = Dict(\n",
    "        \"Intercept\" => 1,\n",
    "        \"Distance\" => 2,\n",
    "        \"DepDelay\" => 3,\n",
    "        \"AA\" => 4,\n",
    "        \"AQ\" => 5,\n",
    "        \"AS\" => 6,\n",
    "        \"B6\" => 7,\n",
    "        \"CO\" => 8,\n",
    "        \"DH\" => 9,\n",
    "        \"DL\" => 10,\n",
    "        \"EV\" => 11,\n",
    "        \"F9\" => 12,\n",
    "        \"FL\" => 13,\n",
    "        \"HA\" => 14,\n",
    "        \"HP\" => 15,\n",
    "        \"MQ\" => 16,\n",
    "        \"NW\" => 17,\n",
    "        \"OH\" => 18,\n",
    "        \"OO\" => 19,\n",
    "        \"TZ\" => 20,\n",
    "        \"UA\" => 21,\n",
    "        \"US\" => 22,\n",
    "        \"WN\" => 23,\n",
    "        \"XE\" => 24,\n",
    "        \"YV\" => 25,\n",
    "        \"Gain\" => 26)\n",
    "# mapping from column to variable names\n",
    "const col2var = map(reverse, var2col)\n",
    "\n",
    "# a custom function to generate [X y] from data table\n",
    "function generate_xy(tbl::NextTable)\n",
    "    # X matrix\n",
    "    XY = zeros(length(tbl), 26)\n",
    "    # intercept term\n",
    "    @views fill!(XY[:, 1], 1)\n",
    "    # Distance term\n",
    "    @views copy!(XY[:, 2], columns(tbl, :Distance))\n",
    "    # DepDelay term\n",
    "    @views copy!(XY[:, 3], columns(tbl, :DepDelay))\n",
    "    # Dummy coding for airline\n",
    "    @inbounds for i in 1:length(tbl)\n",
    "        yrtable[i][:UniqueCarrier] == \"9E\" && continue # base level\n",
    "        XY[i, var2col[tbl[i][:UniqueCarrier]]] = 1\n",
    "    end\n",
    "    # last column is response: gain = depdelay - arrdelay\n",
    "    XY[:, 26] = select(tbl, \n",
    "        (:DepDelay, :ArrDelay) => p -> Float64(p.DepDelay - p.ArrDelay))\n",
    "    # return\n",
    "    XY\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41490375×26 Array{Float64,2}:\n",
       " 1.0   837.0  -4.0  0.0  0.0  0.0  …  0.0  1.0  0.0  0.0  0.0  0.0   -3.0\n",
       " 1.0   837.0  -1.0  0.0  0.0  0.0     0.0  1.0  0.0  0.0  0.0  0.0    2.0\n",
       " 1.0   837.0  29.0  0.0  0.0  0.0     0.0  1.0  0.0  0.0  0.0  0.0    6.0\n",
       " 1.0  1835.0  -2.0  0.0  0.0  0.0     0.0  1.0  0.0  0.0  0.0  0.0    7.0\n",
       " 1.0  1835.0  18.0  0.0  0.0  0.0     0.0  1.0  0.0  0.0  0.0  0.0  -34.0\n",
       " 1.0  1835.0  -4.0  0.0  0.0  0.0  …  0.0  1.0  0.0  0.0  0.0  0.0  -10.0\n",
       " 1.0  1835.0  -4.0  0.0  0.0  0.0     0.0  1.0  0.0  0.0  0.0  0.0    4.0\n",
       " 1.0  1835.0   0.0  0.0  0.0  0.0     0.0  1.0  0.0  0.0  0.0  0.0   -2.0\n",
       " 1.0  1835.0  -4.0  0.0  0.0  0.0     0.0  1.0  0.0  0.0  0.0  0.0  -23.0\n",
       " 1.0   413.0   3.0  0.0  0.0  0.0     0.0  1.0  0.0  0.0  0.0  0.0   -1.0\n",
       " 1.0   413.0  -4.0  0.0  0.0  0.0  …  0.0  1.0  0.0  0.0  0.0  0.0   19.0\n",
       " 1.0   413.0  -3.0  0.0  0.0  0.0     0.0  1.0  0.0  0.0  0.0  0.0   16.0\n",
       " 1.0   413.0   0.0  0.0  0.0  0.0     0.0  1.0  0.0  0.0  0.0  0.0   12.0\n",
       " ⋮                            ⋮    ⋱       ⋮                          ⋮  \n",
       " 1.0   515.0   0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0    5.0\n",
       " 1.0   481.0  57.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  -18.0\n",
       " 1.0   689.0  80.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  -19.0\n",
       " 1.0   270.0  -2.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  -17.0\n",
       " 1.0   425.0  -4.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  -10.0\n",
       " 1.0   546.0  -3.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  -19.0\n",
       " 1.0   215.0  -1.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0   -3.0\n",
       " 1.0   533.0   3.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  -11.0\n",
       " 1.0   874.0  -1.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0    1.0\n",
       " 1.0   545.0  -5.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0   -5.0\n",
       " 1.0   533.0  11.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0    2.0\n",
       " 1.0   874.0   7.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0   12.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy = generate_xy(yrtable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1(3)\n",
    "\n",
    "Review the [Summary of Linear Regression](http://hua-zhou.github.io/teaching/biostatm280-2018spring/slides/12-linreg/linreg.html) and devise a strategy to solve the linear regression.\n",
    "\n",
    "Report the estimated regression coefficients $\\widehat \\beta$, estimated variance $\\widehat \\sigma^2 = \\sum_i (y_i - \\widehat y_i)^2 / (n - 1)$, and coefficient standard errors.\n",
    "\n",
    "Hint: It took my laptop less than 3 minutes to import data and fit linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1(3) Solution:\n",
    "\n",
    "\n",
    "We use sweep operators for solving linear systems on the Gram matrix, $[\\mathbf{{X y}^{T}}][\\mathbf{{X y}]},$ to get the desired quantities from the function `linreg_sweep_all`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "linreg_sweep_all (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using SweepOperator, BenchmarkTools\n",
    "\n",
    "function linreg_sweep_all(y::Vector, X::Matrix)\n",
    "    n = size(X, 1)\n",
    "    p = size(X, 2)\n",
    "    tableau = [X y]' * [X y]\n",
    "    sweep!(tableau, 1:p)\n",
    "    beta_coeff_est = tableau[1:p, end]\n",
    "    sigma_hat2 = tableau[end, end] / (n - 1) \n",
    "    SE_beta_coeff_est = sqrt.(Diagonal( .- sigma_hat2 .* tableau[1:p, 1:p]))\n",
    "    return beta_coeff_est, sigma_hat2, SE_beta_coeff_est\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_coeff_est, sigma_hat2, SE_beta_coeff_est = linreg_sweep_all(xy[:, 26], xy[:, 1:25]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25-element Array{Float64,1}:\n",
       "  1.14033   \n",
       "  0.00164935\n",
       " -0.0118811 \n",
       " -1.8723    \n",
       " -0.5789    \n",
       " -0.938452  \n",
       " -1.42247   \n",
       " -2.57627   \n",
       "  1.16808   \n",
       " -2.19625   \n",
       "  1.03932   \n",
       " -2.15207   \n",
       " -1.35247   \n",
       " -1.87248   \n",
       " -0.350758  \n",
       " -1.46395   \n",
       " -3.62506   \n",
       " -0.00722279\n",
       " -0.40365   \n",
       " -3.5774    \n",
       " -1.14816   \n",
       " -0.883753  \n",
       "  2.74855   \n",
       " -2.56721   \n",
       " -0.202211  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_coeff_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204.4031074256946"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma_hat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25×25 Array{Float64,2}:\n",
       " 0.0202318  0.0         0.0         …  0.0        0.0        0.0      \n",
       " 0.0        4.37958e-6  0.0            0.0        0.0        0.0      \n",
       " 0.0        0.0         6.88878e-5     0.0        0.0        0.0      \n",
       " 0.0        0.0         0.0            0.0        0.0        0.0      \n",
       " 0.0        0.0         0.0            0.0        0.0        0.0      \n",
       " 0.0        0.0         0.0         …  0.0        0.0        0.0      \n",
       " 0.0        0.0         0.0            0.0        0.0        0.0      \n",
       " 0.0        0.0         0.0            0.0        0.0        0.0      \n",
       " 0.0        0.0         0.0            0.0        0.0        0.0      \n",
       " 0.0        0.0         0.0            0.0        0.0        0.0      \n",
       " 0.0        0.0         0.0         …  0.0        0.0        0.0      \n",
       " 0.0        0.0         0.0            0.0        0.0        0.0      \n",
       " 0.0        0.0         0.0            0.0        0.0        0.0      \n",
       " 0.0        0.0         0.0            0.0        0.0        0.0      \n",
       " 0.0        0.0         0.0            0.0        0.0        0.0      \n",
       " 0.0        0.0         0.0         …  0.0        0.0        0.0      \n",
       " 0.0        0.0         0.0            0.0        0.0        0.0      \n",
       " 0.0        0.0         0.0            0.0        0.0        0.0      \n",
       " 0.0        0.0         0.0            0.0        0.0        0.0      \n",
       " 0.0        0.0         0.0            0.0        0.0        0.0      \n",
       " 0.0        0.0         0.0         …  0.0        0.0        0.0      \n",
       " 0.0        0.0         0.0            0.0        0.0        0.0      \n",
       " 0.0        0.0         0.0            0.0209201  0.0        0.0      \n",
       " 0.0        0.0         0.0            0.0        0.0222383  0.0      \n",
       " 0.0        0.0         0.0            0.0        0.0        0.0255715"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full(SE_beta_coeff_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1(4)\n",
    "\n",
    "Go to your resume/cv and claim you have experience performing analytics on data with hundred millions of observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1(4) Solution:\n",
    "\n",
    "\n",
    "I have edited my resume/cv and claimed my experience performing analysis on data with hundred millions of observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2 - Google PageRank\n",
    "\n",
    "We are going to try different numerical methods learnt in class on the [Google PageRank problem](https://en.wikipedia.org/wiki/PageRank)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2(1)\n",
    "\n",
    "Let $\\mathbf{A} \\in \\{0,1\\}^{n \\times n}$ be the connectivity matrix of $n$ web pages with entries\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\ta_{ij}= \\begin{cases}\n",
    "\t1 & \\text{if page $i$ links to page $j$} \\\\\n",
    "\t0 & \\text{otherwise}\n",
    "\t\\end{cases}.\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "$r_i = \\sum_j a_{ij}$ is the out-degree of page $i$. That is $r_i$ is the number of links on page $i$. Imagine a random surfer exploring the space of $n$ pages according to the following rules.  \n",
    "\n",
    "- From a page $i$ with $r_i>0$\n",
    "    * with probability $p$, (s)he randomly chooses a link on page $i$ (uniformly) and follows that link to the next page  \n",
    "    * with probability $1-p$, (s)he randomly chooses one page from the set of all $n$ pages (uniformly) and proceeds to that page  \n",
    "- From a page $i$ with $r_i=0$ (a dangling page), (s)he randomly chooses one page from the set of all $n$ pages (uniformly) and proceeds to that page  \n",
    "    \n",
    "The process defines a Markov chain on the space of $n$ pages. Write down the transition matrix $\\mathbf{P}$ of the Markov chain as a diagonal matrix plus rank-1 matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2(1) Solution:\n",
    "\n",
    ">Since with probability $p$, (s)he randomly chooses a link on page $i$ (uniformly) and follows that link to the next page, if there are ${\\sum_j a_{ij}}$ pages the probability of going to each one would be $\\frac{1}{{\\sum_j a_{ij}}}$.<br> \n",
    "\n",
    ">Additionally, we are given: if there are no links on the current page, with probability $1-p$, (s)he randomly chooses one page from the set of all $n$ pages (uniformly) and proceeds to that page. If there are n total pages in the world, the probability of going to each one would be $1/n$.<br><br>\n",
    "\n",
    ">We note that the transition probability of going from page i to page j is:\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "    p_{ij} = \\begin{cases}\n",
    "    \\frac{1}{\\sum_j a_{ij}}*p + \\frac{1}{n}*(1 - p) & \\text{if page $i$ has links on the page, $r_i$ > 0} \\\\\n",
    "    \\frac{1}{n} & \\text{if there are no links on the page $i$, $r_i$ = 0}\n",
    "    \\end{cases}\n",
    "\\end{eqnarray*}\n",
    "$$<br>\n",
    "> Replacing $r_i = \\sum_j a_{ij}$ we have:\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "    p_{ij} = \\begin{cases}\n",
    "    \\frac{a_{ij}}{r_i}*p + \\frac{1}{n}*(1 - p) & \\text{if page $i$ has links on the page, $r_i$ > 0} \\\\\n",
    "    \\frac{1}{n} & \\text{if there are no links on the page $i$, $r_i$ = 0}\n",
    "    \\end{cases}\n",
    "\\end{eqnarray*}\n",
    "$$<br>\n",
    "\n",
    ">We make note that the structure of transition matrix $P$ is the sum of two terms, a diagonal matrix + a rank-1 matrix, <br> where $\\mathbf{\\frac{1}{n}} = \\frac{1}{n}\\mathbf{1^T}$ and $\\mathbf{\\frac{1-p}{n}} = \\frac{1-p}{n}\\mathbf{1^T}$ are vectors. Then the resulting Transition Probability Matrix is:\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "    \\mathbf{P} = \\begin{cases}\n",
    "     diag(\\frac{p}{r_i})\\mathbf{A} + \\mathbf{\\frac{1-p}{n}}\\mathbf{1} & \\text{if page $i$ has links on the page, $r_i$ > 0} \\\\\n",
    "    diag(0)\\mathbf{A} + \\mathbf{\\frac{1}{n}}\\mathbf{1} & \\text{if there are no links on the page $i$, $r_i$ = 0}\n",
    "    \\end{cases}\n",
    "\\end{eqnarray*}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Q2(2)\n",
    "\n",
    "According to standard Markov chain theory, the (random) position of the surfer converges to the stationary distribution $\\mathbf{x} = (x_1,\\ldots,x_n)^T$ of the Markov chain. $x_i$ has the natural interpretation of the proportion of times the surfer visits page $i$ in the long run. Therefore $\\mathbf{x}$ serves as page ranks: a higher $x_i$ means page $i$ is more visited. It is well-known that $\\mathbf{x}$ is the left eigenvector corresponding to the top eigenvalue 1 of the transition matrix $\\mathbf{P}$. That is $\\mathbf{P}^T \\mathbf{x} = \\mathbf{x}$. Therefore $\\mathbf{x}$ can be solved as an eigen-problem. Show that it can also be cast as solving a linear system. Since the row sums of $\\mathbf{P}$ are 1, $\\mathbf{P}$ is rank deficient. We can replace the first equation by the $\\sum_{i=1}^n x_i = 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2(2) Solution:\n",
    "\n",
    ">First we have:\n",
    "$$\\mathbf{P}^T \\mathbf{x} = \\mathbf{x}$$<br>\n",
    ">Moving everything to the left side we have:\n",
    "$$\\mathbf{P}^T \\mathbf{x} - \\mathbf{x} = \\mathbf{0}$$<br>\n",
    ">We can re-write this as:\n",
    "$$(\\mathbf{I} - \\mathbf{P}^T) \\mathbf{x} = \\mathbf{0}$$<br>\n",
    ">Now, we see that this problem can also be cast as solving a linear system. What we want to find is the solution `x`.\n",
    ">If we let $\\mathbf{C} = (\\mathbf{I} - \\mathbf{P}^T),$ we know $\\mathbf{C}$ is not full rank. Since the row sums of $\\mathbf{P}$ are 1, $\\mathbf{P}$ is rank deficient and we know each column of $\\mathbf{C}$ will also sum to 1.<br><br>\n",
    ">Thus, we can replace the first equation by the $\\sum_{i=1}^n x_i = 1$ by replacing the first row of $\\mathbf{C}$ with a vector of ones, and create a new vector for the solution, where the first postition is a 1 (indicating we changed the 1st row of matrix $\\mathbf{C}$ to ones) and the rest are zeros. <br><br>\n",
    ">Note that we could choose any of the n rows of matrix $\\mathbf{C}$ to be ones, adjusting the corresponding solution vector with a 1 in the position of the row number that was changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2(3)\n",
    "\n",
    "Download the [`ucla.zip`](http://hua-zhou.github.io/teaching/biostatm280-2018spring/hw/hw3/ucla.zip) package from course webpage. Unzip the package, which contains two files `U.txt` and `A.txt`. `U.txt` lists the 500 URL names. `A.txt` is the $500 \\times 500$ connectivity matrix. Read data into Julia. Compute summary statistics:\n",
    "* number of pages\n",
    "* number of edges\n",
    "* number of dangling nodes (pages with no out links)\n",
    "* which page has max in-degree?\n",
    "* which page has max out-degree?\n",
    "* visualize the sparsity pattern of $\\mathbf{A}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2(3) Solution:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_pages = size(A, 1) = 500\n",
      "n_edges = countnz(A) = 10853\n",
      "n_dangling_nodes = n_pages - countnz(r) = 103\n"
     ]
    }
   ],
   "source": [
    "# connectivity matrix\n",
    "A = readcsv(\"A.txt\")\n",
    "# U = readcsv(\"U.txt\")\n",
    "U = readlines(\"U.txt\")\n",
    "# Make diagonals 0 so that probability of going from page i to page i is 0 !\n",
    "A = A - Diagonal(A)\n",
    "# Let Julia know A is a sparse matrix since most entries are 0's!\n",
    "A = sparse(A);\n",
    "# number of pages\n",
    "@show n_pages = size(A, 1)\n",
    "# number of edges (page links)\n",
    "@show n_edges = countnz(A)\n",
    "# number of dangling nodes (pages with no out links)\n",
    "r = sum(A, 2) #number of outlinks per page\n",
    "@show n_dangling_nodes = n_pages - countnz(r); # total number of pages minus those with out links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are `n_pages = 500` pages, there are `n_edges = 10,853` edges, and there are `n_dangling_nodes = 103` dangling nodes (pages with no out links) in the connectivity matrix in `A.txt`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max in/out-degree\n",
    "\n",
    "Next we find which page has the max in-degree and which page has the max out-degree. The in-degree of page `i` is defined to be the number of pages that link to page `i`. Similarly, the out-degree of page `i` is defined to be the number of page links on page `i`. Thus, we are interested in which page has the most traffic coming in, and which page has the most traffic going out by calculing the maximum in/out degree.\n",
    "\n",
    "We see that the page that has the most traffic coming in is \"http://www.ucla.edu\", with 171 pages linking in to it. \n",
    "We see that the page that has the most traffic going out is \"http://giveto.ucla.edu\", with 87 pages linking in to it. Makes total sense to me lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "which_max_nidgl = indmax(n_in_degree_links) = 1\n",
      "max_in_degree_link = U[which_max_nidgl] = \"http://www.ucla.edu\"\n",
      "max_n_in_degree_links = n_in_degree_links[which_max_nidgl] = 171.0\n"
     ]
    }
   ],
   "source": [
    "# which page has max in-degree?\n",
    "n_in_degree_links = sum(A, 1)\n",
    "@show which_max_nidgl = indmax(n_in_degree_links) #indicates first link has the maximum # of in-degree links\n",
    "@show max_in_degree_link = U[which_max_nidgl] #print the first link in URL file\n",
    "@show max_n_in_degree_links = n_in_degree_links[which_max_nidgl]; # number of in-degree links to this page is 171!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U[which_max_nodgl] = \"http://giveto.ucla.edu\"\n",
      "r[which_max_nodgl] = 87.0\n"
     ]
    }
   ],
   "source": [
    "# which page has max out-degree?\n",
    "which_max_nodgl = indmax(r)\n",
    "@show U[which_max_nodgl]\n",
    "@show r[which_max_nodgl];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Sparsity Pattern of Connectivity Matrix\n",
    "\n",
    "Below, we use the spy() function in the `Plots.jl` package to visualize the sparsity of the connectivity matrix A in `A.txt`. The shaded cells of the figure below represent where A[i,j] = 1 and there exists a link from page `i` to `j`. The unshaded cells show where A[i, j] = 0 and there does not exists a link from page `i` to `j`.\n",
    "\n",
    "Looking across the graph, each row `i` without any shading indicate pages where there are no out-links on page `i`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 600 400\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip9600\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"600\" height=\"400\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polygon clip-path=\"url(#clip9600)\" points=\"\n",
       "0,400 600,400 600,0 0,0 \n",
       "  \" fill=\"#ffffff\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip9601\">\n",
       "    <rect x=\"120\" y=\"0\" width=\"421\" height=\"400\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polygon clip-path=\"url(#clip9600)\" points=\"\n",
       "126.039,375.869 490.096,375.869 490.096,11.811 126.039,11.811 \n",
       "  \" fill=\"#ffffff\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip9602\">\n",
       "    <rect x=\"126\" y=\"11\" width=\"365\" height=\"365\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip9600)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  126.039,375.869 490.096,375.869 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9600)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  126.039,11.811 126.039,375.869 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9600)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  198.486,375.869 198.486,370.408 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9600)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  271.298,375.869 271.298,370.408 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9600)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  344.109,375.869 344.109,370.408 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9600)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  416.921,375.869 416.921,370.408 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9600)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  489.732,375.869 489.732,370.408 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9600)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  126.039,84.2585 131.499,84.2585 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9600)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  126.039,157.07 131.499,157.07 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9600)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  126.039,229.882 131.499,229.882 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9600)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  126.039,302.693 131.499,302.693 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9600)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  126.039,375.505 131.499,375.505 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip9600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:middle;\" transform=\"rotate(0, 198.486, 389.669)\" x=\"198.486\" y=\"389.669\">100</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip9600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:middle;\" transform=\"rotate(0, 271.298, 389.669)\" x=\"271.298\" y=\"389.669\">200</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip9600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:middle;\" transform=\"rotate(0, 344.109, 389.669)\" x=\"344.109\" y=\"389.669\">300</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip9600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:middle;\" transform=\"rotate(0, 416.921, 389.669)\" x=\"416.921\" y=\"389.669\">400</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip9600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:middle;\" transform=\"rotate(0, 489.732, 389.669)\" x=\"489.732\" y=\"389.669\">500</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip9600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:end;\" transform=\"rotate(0, 120.039, 88.7585)\" x=\"120.039\" y=\"88.7585\">100</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip9600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:end;\" transform=\"rotate(0, 120.039, 161.57)\" x=\"120.039\" y=\"161.57\">200</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip9600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:end;\" transform=\"rotate(0, 120.039, 234.382)\" x=\"120.039\" y=\"234.382\">300</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip9600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:end;\" transform=\"rotate(0, 120.039, 307.193)\" x=\"120.039\" y=\"307.193\">400</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip9600)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:12; text-anchor:end;\" transform=\"rotate(0, 120.039, 380.005)\" x=\"120.039\" y=\"380.005\">500</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip9602)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  126.039,11.811 490.096,11.811 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip9602)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  490.096,11.811 490.096,375.869 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip9602)\">\n",
       "<image width=\"364\" height=\"364\" xlink:href=\"data:image/png;base64,\n",
       "iVBORw0KGgoAAAANSUhEUgAAAWwAAAFsCAYAAADon4O5AAAMY0lEQVR4nO3d626jOhQGUDLq+79y\n",
       "zo9RNBwKwYBv215LqhqlaUgb87GzMbAsAAAwqPfDn99a1k/GJwWYzXtZllfCY7Is60+mJwKgjNeS\n",
       "t2IHmMp7873GshYVNsB9Z+2QI7eCXmAD3Pekwr78uwIb4L67FfbZ7+6G+ZOF9SZlby1ADp+8Ocqd\n",
       "9f1XKmk7GAEys9MRIJicn+pPw19gA/ThNPwFNsB9VfvNAhsgvyJBLrAB8nva2zZTBCCTp4F65ffN\n",
       "EgHI4G5wn8233v2ZwAYIQmADADCsmjsF7YAEeKDmJcIAeKDmuUQAeKBJUNvpCHDfUXA70hEgiCLn\n",
       "5h8psPWSgKGNFNgAQxPYAAAMyyyRh/SwgdrkDgDQnooEbvqzWIEAYBo2+lBJiZXNCgwAHbKBBr4S\n",
       "EsBUPheCzHmikk+QFjn5CV3b24gaBxBIqUq45mXmAbpQOrgEI6UZYwBAX3JUJ++dr9LLhGX5PZaM\n",
       "LQCgrdZ78LczVK5WR61fP9flnpUE0+jx9KpW5rF5f0n13tzudcZZNT0GNsAVTwM3TBEhsIHoUgM3\n",
       "TCV9RGADswhTSR9p+QfsHcJupyNw1TQ7sltW2FP8g/kl/MdSHinx/k+TJT22RKb550/K+zu3K+9/\n",
       "7lki4YsFLRGAIHpsiQhhYFnqzcMOo8eWyPRvyuC8v6R6bW5PX8y1DGwr7pymX+moZriM0RIBRrFt\n",
       "mwyXJT22RADu+lz2cEgCGxjF0GG9LAIbGMfQYb0sy/LT+gXsGP6fPrlpDiOmuuHHlVki1Db8SkV1\n",
       "02SJlgjQs5QwnqYI6HFaH2ObphoiCzmxoiVCbVZAcpgyP7REgIim3PD32BKZ8o0Aftme/Gl6Kmwg\n",
       "guEPigFgIK3bD9uDKFzAYHwOnAGAAbhQwRc9XCLsCZUaAAAAENzVFok+F4zD+pzAPGygB+ZZJxDY\n",
       "QC9MIkjwdKt2dvjoO/FxT5b/7Sv38gCaUGEDBCGwAYIQ2ABBtG7y751L5Mre4tavHyhnnQ+fTHiy\n",
       "zjuPDUBGziUCwBhybM2OptOVXCYsy++xZGwxrE+/uEZfp4f+Ua8r87ZPl/JYYDI/rV8A0LUnRU7N\n",
       "gnAKpvUBJTg3SAECG8hNWBcisIGchHVBeth9MdjpzVn/ea9HrWddiMDui7CmNylj8uwIZQGeicDu\n",
       "iwqb3uydOiLlsRSghw2kSmmPUJDABnJRYRcmsAGCENgAQQhsgCAENkAQAhsgCIENpHon3AYAAAAA\n",
       "AAAAAAAAgG5EPh3i2cnUS/8+XFXjAJPUMf15LWcXzbCOdGbWo5Rm/buB55rkR+StpwqbaHqqsNdU\n",
       "2EE4lwiMb++8Hz5hEooBC4QS+arpWhpE06ol8v7ys/XPU58PLlMhA1OJXGE/pUKntpY7Hb+NdxV2\n",
       "EHY6whwE7wAENoxJy3BAAhvGpKIekMAGCEJgw5zei7ZJODPPEoHRXGmDaJkEpMKGMZydde/sdz9f\n",
       "yyLMu6XChviehPXec62/0xGBDeXUODgrR1g7cCYILREop/ewttMxGIENMeWorFXPwQhsiCdnz5pA\n",
       "BDbEIqwnJrAhjlJhbVpfEGaJQAwlK+vt86rgO6XChv6Vng2iwg5ChQ19uxPW2/nfZwGswg5ChQ39\n",
       "ultZp1TITv4UkMCmJgGRrlTPen1BXq2PYAQ2NQmINCV3MK7fAxvQYAQ29KXmPGsb0GAENvTDQTF8\n",
       "JbChD8KaU7UC20CEY8KaJLUCW68M9glrkmmJQDvCGgAAAAAA4IsaO1LsrKGmvTPaGYMAAAAAAADQ\n",
       "gB11AEA1Cg8AAKAhH0mAqThPNfzf1UIgdR16X3gsVOXQdEazd2g6DMFgZgbGOQAAAJBIGwEmZMUn\n",
       "EuOVbhmcAAAAAAAAAAC9eW++nz1275wKe18pyzy7j30p/+Oa7o6dEowthpZzMD8J7DvLAvpnXc3k\n",
       "teQ97ePnjXEaSVq6EhCfsWrsMp3UFcUWFwCAMWmJMKKUT3DrsW/cEsKf1i8AGliH9JpWHV0T2Mzm\n",
       "KKyhewKbmQhrQhPYjO61+v7e3L/tWeth0zWBzei2OxbX96u2CUVgMzptEIZRK7CvnK+EMbWoaIU1\n",
       "Q/mptJzX5jvzafHeC2uGoiVCb3KErMIAAGhne6ayEs8NQGZPQvvqBQyYz/vgdmSj/B0EoYdNLa+D\n",
       "25GN8ncQSNQqIerrBuiCEAUAgBJV8Z3nVJ3HtT6S1c5nRrId2+v7qqt1pGMKO3DiSnnvXNWFiPaO\n",
       "0m42htcLfnKpsL0tjhUTICPT+gCCENgAQQhsgCAENkAQAhsgCIENEITABgii9jUdAQAAADqQ49D0\n",
       "o3aHQ9MBMrLTkVpaXiIs5Sxr9rPQPSd/AvjrSQZW8Vqev8h1WL8Wp9Gc2ZWxVLKiNfYAAO7QcwSA\n",
       "QmxkGYFxDAAAAFBPrulP5mEDAAAAAAA9Mi8VAAAAAG57L1psh1zAACCQp1uzsyuJ7F3tI+cWdL1F\n",
       "fu985V4eQBMqbAAAAGBSV/u728f30sM++sq9PIAm7vSwnYVvDqZXQWd+Wr8AumXDDABwV+rH3qPH\n",
       "6WGPQxsEKEKwAADQp5RK9dtjtETi8/+BIK4Gdmp4lyZk+DAWmMJr+TvYn0zhWv/+3nN97jt73JPl\n",
       "f5Pjb+xRrpAa7f8CwzIPOy5BC5Nxtj4AAADqsUOTroxyxRnT+oCh6WEDBCGwucInFWhIYHOFqYQA\n",
       "ACnsdAQIQEsEIAiBDQDs0p6CB/SwAQLQEgEIovW82u15qtfnzk7R+vUD5WzPob8s1nktEYAIXMAg\n",
       "NledgYkI7NgELUzETkcAAABgQp8pdDV6obWWc/YaerSd2rj3c9OaYHK5e9i9BmJkV+al3+V9AwDI\n",
       "RUukD3stkaPKuvX/EGjEtL4+1WiDAABQgpZIH85miRw9FnrXw3o/jJlaIr2GNYxMWAMAAAAAAAAA\n",
       "wCXmYffBPGyi6WF9ns5M87BbM7gZxSesUwqgXoukkAR2HSmD28Amitfme8pjyUBgl5daiRjYwFcC\n",
       "uyxn3QOyEdjl3Alr4c5ojOmMBHYZdytrbRFGY0xnJLDz0wZhNHvj2RhvQGDn9SSsrQD0aq9K/txn\n",
       "3FYksPN5Wln76EhExm1FAjsPbRBm9T64TQEC+zlhzcxeB7cpQGA/I6yZmbFfmcC+T1gzOxV1ZQL7\n",
       "HmHNbIz3Dgjs64Q1M1JNd0BgX1MyrG0EiMi4rUhgpytdWatgiGK9Hhi3FQnsNNog8M9RSFtHChPY\n",
       "54Q1pFFtFyawvxPWQDcE9jFhDXRFYO8T1kB3BPZvwhroksD+v9ZhbUPBaIzpjAT2P63D+vMaYCTG\n",
       "dEYC+68ewhrgK4EtrOGu92LdAQAAAGAcel0AAIzvM0OixlzJWss5ew09S5mx0vp/CHBZ7+HLb94z\n",
       "eOjpSvQ+uL297+xxd5d99pVzeQDNRD9w5qw9oH1QZkMJNBA9sL9xBONfr4PbQDCjBrawBoYzYmAL\n",
       "a2BIowW2sAaGpacJcF2TwnAd2E8ObNl78TYGrPVw4BR8cyWEjWWARkK0UnMcmr7+/b3n+tx39rgn\n",
       "y09hiwgAQHmtq85tpb2uxr+pedIqoI3tp/Jlyb/Ol3reIiJO6zN1D1i7mwefDUKIsF6WeIEtrIGt\n",
       "1MDdnlcnTFB/tHzBex9FvoXxXliH+4cD2V0J35BB/dGywj76p+3dr7KG+Wwr4qMMSAngz++HDetl\n",
       "idESEdbAXetP8qHDeln6b4mchXX4NwAoItTsj1Q/DZd9FMbrKXsqayDFFPu3Wgb2URgLa+DjW995\n",
       "/bMhA3qrxx62sAZSTBHSa70FtrAG1vZC+duMEQBor/VHiqNzBTgDH+A8+xstdzpufYLaR52xhT94\n",
       "gSqMEwAAyMGn7C9c0xEAAHK6UgWfHXF09fn2nvPqUY6qeLbsrOpXynrtvftitktt9dob205tTHks\n",
       "1JBjnTFmAZjLlcru7nMDAMA8nkzjS7n8vIsPAGQy205HOFNyx7T1jEdynEtkW20blLT2JHSNX7qV\n",
       "6+RPe2faM/Dnk7rBLj290thjWLXnJvc6F5o6vP8AwNhK7HTUEpnD3vvsJGBQUE8XMGBc6yAX4HCT\n",
       "wKY0M4cgo6c7gd4Ht7f3nT3uyfLfm9vb57ej67n3cvz/BSoYqcI+CmnV3XOqZOjAn9YvgBCENXRg\n",
       "pAqb5+wchI4JbJZF+whCENhx5dzxJ6ghAIEdk52AMCE7HeMR1jCp6IGd0hYYbc6wsIZJtVz5XY0Z\n",
       "4IKSlwg7C2RhCwAAADTyHw8376M1nBsKAAAAAElFTkSuQmCC\n",
       "\" transform=\"translate(126, 12)\"/>\n",
       "</g>\n",
       "</svg>\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Plots\n",
    "spy(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2(4)\n",
    "\n",
    "Set the _teleportation_ parameter at $p = 0.85$. Try the following methods to solve for $\\mathbf{x}$ using the `ucla.zip` data.\n",
    "\n",
    "0. A dense linear system solver such as LU decomposition.  \n",
    "0. A simple iterative linear system solver such as Jacobi or Gauss-Seidel.   \n",
    "0. A dense eigen-solver.  \n",
    "0. A simple iterative eigen-solver such as the power method.  \n",
    "\n",
    "For iterative methods, you can use the [`IterativeSolvers.jl`](https://github.com/JuliaMath/IterativeSolvers.jl) package. Make sure to utilize the special structure of $\\mathbf{P}$ (diagonal + rank 1) to speed up the matrix-vector multiplication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2(4) Solution:\n",
    "\n",
    "Below we use four different methods to solve for the stationary distribution, `x`, the long run proportion of time spent on each page. I have written a function for each method of solving this problem, where by default the teleportation parameter is set at p = 0.85. For the iterative solving methods, our functions set by default the maximum number of iterations to 10,000 and we use a tolerance of 1e-9. \n",
    "        x_old::Vector = repeat([1/size(A, 1)], outer=[size(A, 1)])\n",
    "\n",
    ". Using the `ucla.zip` data, we benchmark these methods to compare their efficiencies. \n",
    "\n",
    "### Using LU-decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LU_Decomposition_Linear_Solver (generic function with 2 methods)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function LU_Decomposition_Linear_Solver(A::AbstractMatrix, telep::Float64 = 0.85)\n",
    "#first make P\n",
    "# Matrix P is the sum of a sparse matrix + a rank 1 matrix\n",
    "n = size(A, 1)\n",
    "r = sum(A, 2) #sum each row of A to get r_i for each page i\n",
    "P = zeros(n, n)\n",
    "term1 = zeros(n)\n",
    "term2 = repeat([1 / n], outer = [n]) \n",
    "for i in 1:n\n",
    "    if r[i] > 0 \n",
    "        term1[i] = telep / r[i]\n",
    "        term2[i] = (1 - telep) / n\n",
    "    end\n",
    "end\n",
    "#first make P^T\n",
    "P_transpose = (Diagonal(term1) * full(A) .+ term2).'\n",
    "\n",
    "#then make C = (I- P^t)\n",
    "C = I - P_transpose\n",
    "C[1, : ] = ones(n)      \n",
    "b = zeros(n)\n",
    "b[1] = 1.0\n",
    "\n",
    "#use the fact that each column sums to 1 and replace the first row of C with ones\n",
    "#then solve x = C \\ [1, 0, ... , 0] \n",
    "    return C \\ b\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500-element Array{Float64,1}:\n",
       " 0.0127701 \n",
       " 0.00130393\n",
       " 0.00405405\n",
       " 0.00398338\n",
       " 0.00130393\n",
       " 0.00130393\n",
       " 0.00130393\n",
       " 0.00130393\n",
       " 0.00130393\n",
       " 0.00130393\n",
       " 0.00130393\n",
       " 0.00145083\n",
       " 0.00141309\n",
       " ⋮         \n",
       " 0.0011959 \n",
       " 0.00149245\n",
       " 0.0011959 \n",
       " 0.00345944\n",
       " 0.00211007\n",
       " 0.0011959 \n",
       " 0.0011959 \n",
       " 0.0084935 \n",
       " 0.0011959 \n",
       " 0.00149103\n",
       " 0.0011959 \n",
       " 0.0011959 "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_LU = LU_Decomposition_Linear_Solver(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2(5)\n",
    "\n",
    "List the top 20 ranked URLs you found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first concatenate 1:n and then sort and then get indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mUndefVarError: x not defined\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mUndefVarError: x not defined\u001b[39m",
      ""
     ]
    }
   ],
   "source": [
    "using DataFrames\n",
    "n = size(A, 1)\n",
    "indices = collect(1 : n)\n",
    "x_with_indices = hcat(x, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mUndefVarError: x_with_indices not defined\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mUndefVarError: x_with_indices not defined\u001b[39m",
      ""
     ]
    }
   ],
   "source": [
    "sorted = sortrows(x_with_indices, rev = true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that there is a 4 way tie between the 19th - 22nd sites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mUndefVarError: sorted not defined\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mUndefVarError: sorted not defined\u001b[39m",
      ""
     ]
    }
   ],
   "source": [
    "top22 = sorted[1:22, 1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mUndefVarError: top22 not defined\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mUndefVarError: top22 not defined\u001b[39m",
      ""
     ]
    }
   ],
   "source": [
    "top22_indices = convert(Array{Int64}, top22[1:22, 2])\n",
    "top22_pages = U[top22_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jacobi Iterative Method\n",
    "\n",
    ">Note that for our problem we are finding the solution $\\mathbf{x}$ to the equation $\\mathbf{C}\\mathbf{x} = \\mathbf{b},$\n",
    "where $\\mathbf{C} = (\\mathbf{I} - \\mathbf{P^{T}})$\n",
    "\n",
    "$$x_i^{(t+1)} = \\frac{b_i - \\sum_{j=1}^{i-1} c_{ij} x_j^{(t)} - \\sum_{j=i+1}^n c_{ij} x_j^{(t)}}{c_{ii}}$$\n",
    "\n",
    "Splitting up Matrix A into the sum of a Lower Triangular, Diagonal and Upper triangular matrix we have: \n",
    "$$\\mathbf{C} = \\mathbf{L} + \\mathbf{D} + \\mathbf{U}$$<br>\n",
    "$$x_i^{(t+1)} = -\\mathbf{D^{-1}}\\mathbf{C}x_i^{(t)} + x_i^{(t)} + \\mathbf{D^{-1}}\\mathbf{b}$$\n",
    "\n",
    ">Now substituting back in $\\mathbf{C} = (\\mathbf{I} - \\mathbf{P^{T}})$ we have:\n",
    "$$x_i^{(t+1)} = -\\mathbf{D^{-1}}(\\mathbf{I} - \\mathbf{P^{T}})x_i^{(t)} + x_i^{(t)} + \\mathbf{D^{-1}}\\mathbf{b}$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Jacobi_Linear_Solver (generic function with 2 methods)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function Jacobi_Linear_Solver(A::AbstractMatrix, telep::Float64 = 0.85; \n",
    "        maxiter::Int = 10000, tolerance::Float64 = 1e-9, \n",
    "        x_old::Vector = repeat([1/size(A, 1)], outer=[size(A, 1)]))\n",
    "#first make P\n",
    "# Matrix P is the sum of a sparse matrix + a rank 1 matrix\n",
    "n = size(A, 1)\n",
    "r = sum(A, 2) #sum each row of A to get r_i for each page i\n",
    "P = zeros(n, n)\n",
    "term1 = zeros(n)\n",
    "term2 = repeat([1/n], outer=[n]) \n",
    "for i in 1:n\n",
    "    if r[i] > 0 \n",
    "        term1[i] = telep / r[i]\n",
    "        term2[i] = (1 - telep) / n\n",
    "    end\n",
    "end\n",
    "#first make P^T\n",
    "P_transpose = (Diagonal(term1) * sparse(A) .+ term2).'\n",
    "\n",
    "#then make C = (I- P^t)\n",
    "C = I - P_transpose\n",
    "b = zeros(n)\n",
    "    \n",
    "x_new = zeros(n)\n",
    "\n",
    "D_inv = inv(Diagonal(C)) \n",
    "for i in 1:maxiter\n",
    "x_new = -D_inv * (C * x_old) .+ x_old .+ (D_inv * b)\n",
    "if vecnorm(x_new - x_old) < tolerance\n",
    "        break\n",
    "    end\n",
    "x_old = x_new       \n",
    "end\n",
    "return x_new\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500-element Array{Float64,1}:\n",
       " 0.012771  \n",
       " 0.00130402\n",
       " 0.00405434\n",
       " 0.00398366\n",
       " 0.00130402\n",
       " 0.00130402\n",
       " 0.00130402\n",
       " 0.00130402\n",
       " 0.00130402\n",
       " 0.00130402\n",
       " 0.00130402\n",
       " 0.00145093\n",
       " 0.00141319\n",
       " ⋮         \n",
       " 0.00119598\n",
       " 0.00149255\n",
       " 0.00119598\n",
       " 0.00345969\n",
       " 0.00211022\n",
       " 0.00119598\n",
       " 0.00119598\n",
       " 0.00849411\n",
       " 0.00119598\n",
       " 0.00149114\n",
       " 0.00119598\n",
       " 0.00119598"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_jacobi = Jacobi_Linear_Solver(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.490383853180799e-6"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecnorm(x_LU - x_jacobi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense Eigen-Solver\n",
    "\n",
    "It is well-known that $\\mathbf{x}$ is the left eigenvector corresponding to the top eigenvalue 1 of the transition matrix $\\mathbf{P}$. That is $\\mathbf{P}^T \\mathbf{x} = \\mathbf{x}$. Therefore $\\mathbf{x}$ can be solved as an eigen-problem.\n",
    " \n",
    "We first perform eigen decomposition on $P^{T}$ to get the left eigenvector corresponding to the top eigenvalue 1, and find vector $x_i$, the proportion of times the surfer visits page $i$ in the long run. Therefore `x_dense_eigen_solvers` serves as page ranks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dense_Eigen_Solver (generic function with 2 methods)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function Dense_Eigen_Solver(A::AbstractMatrix, telep::Float64 = 0.85)\n",
    "#first make P\n",
    "# Matrix P is the sum of a sparse matrix + a rank 1 matrix\n",
    "n = size(A, 1)\n",
    "r = sum(A, 2) #sum each row of A to get r_i for each page i\n",
    "P = zeros(n, n)\n",
    "term1 = zeros(n)\n",
    "term2 = repeat([1/n], outer=[n]) \n",
    "for i in 1:n\n",
    "    if r[i] > 0 \n",
    "        term1[i] = telep / r[i]\n",
    "        term2[i] = (1 - telep) / n\n",
    "    end\n",
    "end\n",
    "eigenvals_weights = zeros(n)\n",
    "#first make P^T\n",
    "P_transpose = (Diagonal(term1) * full(A) .+ term2).'\n",
    "# eig-decomposition C\n",
    "C = eigfact((P_transpose)) # this gets the eigen decomp of P^T which has the eigen values and vectors\n",
    "    \n",
    "# we get the real elements of the first column of eigenvectors \n",
    "eigenvals_weights = real(C[:vectors][:, 1]) \n",
    "    \n",
    "# use eigen solvers to get the long run frequency of each page\n",
    "return eigenvals_weights / sum(eigenvals_weights) # find the proportion of time spent in each page over total time\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500-element Array{Float64,1}:\n",
       " 0.0127701 \n",
       " 0.00130393\n",
       " 0.00405405\n",
       " 0.00398338\n",
       " 0.00130393\n",
       " 0.00130393\n",
       " 0.00130393\n",
       " 0.00130393\n",
       " 0.00130393\n",
       " 0.00130393\n",
       " 0.00130393\n",
       " 0.00145083\n",
       " 0.00141309\n",
       " ⋮         \n",
       " 0.0011959 \n",
       " 0.00149245\n",
       " 0.0011959 \n",
       " 0.00345944\n",
       " 0.00211007\n",
       " 0.0011959 \n",
       " 0.0011959 \n",
       " 0.0084935 \n",
       " 0.0011959 \n",
       " 0.00149103\n",
       " 0.0011959 \n",
       " 0.0011959 "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_dense_eigen_solvers = Dense_Eigen_Solver(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  17.41 MiB\n",
       "  allocs estimate:  1952\n",
       "  --------------\n",
       "  minimum time:     90.286 ms (0.00% GC)\n",
       "  median time:      101.463 ms (1.67% GC)\n",
       "  mean time:        107.280 ms (2.73% GC)\n",
       "  maximum time:     148.296 ms (38.43% GC)\n",
       "  --------------\n",
       "  samples:          47\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark Dense_Eigen_Solver(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9112447522968875e-16"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecnorm(x_LU - x_dense_eigen_solvers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Power_Eigen_Solver69 (generic function with 2 methods)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function Power_Eigen_Solver69(A::AbstractMatrix, telep::Float64 = 0.85; \n",
    "        maxiter::Int = 10000, tolerance::Float64 = 5e-7, \n",
    "        x_old::Vector = repeat([1/size(A, 1)], outer=[size(A, 1)]))\n",
    "#first make P\n",
    "# Matrix P is the sum of a sparse matrix + a rank 1 matrix\n",
    "n = size(A, 1)\n",
    "r = sum(A, 2) #sum each row of A to get r_i for each page i\n",
    "P = zeros(n, n)\n",
    "term1 = zeros(n)\n",
    "term2 = repeat([1 / n], outer = [n]) \n",
    "for i in 1:n\n",
    "    if r[i] > 0 \n",
    "        term1[i] = telep / r[i]\n",
    "        term2[i] = (1 - telep) / n\n",
    "    end\n",
    "end\n",
    "\n",
    "#first make P^T\n",
    "#P_transpose = (Diagonal(term1) * sparse(A) .+ term2).' # blas2 here so use rank one update\n",
    "#P_term1 = At_mul_B(full(A), Diagonal(term1))\n",
    "P_term1 = sparse(A') * Diagonal(term1)\n",
    "P_term2 = ones(n, 1) * term2'\n",
    "P_t2vector = P_term2[1, :]' #want to make this a vector to speed up the process and reduce memory size\n",
    "    \n",
    "x_new = vec(zeros(n))\n",
    "\n",
    "for i in 1:maxiter\n",
    "#x_new = P_transpose * x_old\n",
    "x_new = P_term1*x_old .+ (P_t2vector * x_old) \n",
    "        \n",
    "if vecnorm(x_new - x_old) < tolerance\n",
    "        break\n",
    "    end\n",
    "x_old = x_new       \n",
    "end\n",
    "return x_new / sum(x_new)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500-element Array{Float64,1}:\n",
       " 0.0127701 \n",
       " 0.00130394\n",
       " 0.00405407\n",
       " 0.0039834 \n",
       " 0.00130394\n",
       " 0.00130394\n",
       " 0.00130394\n",
       " 0.00130394\n",
       " 0.00130394\n",
       " 0.00130394\n",
       " 0.00130394\n",
       " 0.00145083\n",
       " 0.00141309\n",
       " ⋮         \n",
       " 0.0011959 \n",
       " 0.00149245\n",
       " 0.0011959 \n",
       " 0.00345947\n",
       " 0.00211009\n",
       " 0.0011959 \n",
       " 0.0011959 \n",
       " 0.00849357\n",
       " 0.0011959 \n",
       " 0.00149104\n",
       " 0.0011959 \n",
       " 0.0011959 "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_Power69 = Power_Eigen_Solver69(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  13.42 MiB\n",
       "  allocs estimate:  1486\n",
       "  --------------\n",
       "  minimum time:     4.849 ms (0.00% GC)\n",
       "  median time:      7.109 ms (18.98% GC)\n",
       "  mean time:        6.970 ms (16.57% GC)\n",
       "  maximum time:     17.801 ms (12.40% GC)\n",
       "  --------------\n",
       "  samples:          716\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using BenchmarkTools\n",
    "@benchmark LU_Decomposition_Linear_Solver(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vecnorm(x_LU - x_jacobi) = 1.8411166472281638e-9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  14.93 MiB\n",
       "  allocs estimate:  5212\n",
       "  --------------\n",
       "  minimum time:     12.791 ms (0.00% GC)\n",
       "  median time:      17.743 ms (6.40% GC)\n",
       "  mean time:        17.876 ms (5.87% GC)\n",
       "  maximum time:     26.267 ms (7.75% GC)\n",
       "  --------------\n",
       "  samples:          280\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@show vecnorm(x_LU - x_jacobi)\n",
    "@benchmark Jacobi_Linear_Solver(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vecnorm(x_LU - x_dense_eigen) = 2.9112447522968875e-16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  17.40 MiB\n",
       "  allocs estimate:  1951\n",
       "  --------------\n",
       "  minimum time:     90.008 ms (0.00% GC)\n",
       "  median time:      98.755 ms (1.55% GC)\n",
       "  mean time:        100.723 ms (2.61% GC)\n",
       "  maximum time:     152.645 ms (36.88% GC)\n",
       "  --------------\n",
       "  samples:          50\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@show vecnorm(x_LU - x_dense_eigen)\n",
    "@benchmark Dense_Eigen_Solver(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vecnorm(x_LU - x_Power69) = 8.866001341035277e-7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  4.75 MiB\n",
       "  allocs estimate:  3262\n",
       "  --------------\n",
       "  minimum time:     1.448 ms (0.00% GC)\n",
       "  median time:      1.845 ms (0.00% GC)\n",
       "  mean time:        2.098 ms (15.16% GC)\n",
       "  maximum time:     5.358 ms (45.36% GC)\n",
       "  --------------\n",
       "  samples:          2376\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@show vecnorm(x_LU - x_Power69)\n",
    "@benchmark Power_Eigen_Solver69(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2(6)\n",
    "\n",
    "As of Monday May 11 2018, there are at least 1.83 billion indexed webpages on internet according to <http://www.worldwidewebsize.com/>. Explain whether each of these methods works for the PageRank problem at this scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2(6) Solution:\n",
    "\n",
    "0. A dense linear system solver - LU decomposition  (dont work)\n",
    "0. A simple iterative linear system solver - Jacobi  (work)\n",
    "0. A dense eigen - solver (dont work)\n",
    "0. A simple iterative eigen-solver - the power method  (work)\n",
    "\n",
    "Consider the Google PageRank problem. We want to find the top left eigenvector of the transition matrix  P . Direct methods such as (unsymmetric) QR or SVD takes forever. Iterative methods such as power method is feasible. However power method may take a large number of iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Indexed Web contains at least 3.07 billion pages (Thursday, 24 May, 2018)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "87px",
    "width": "252px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
